{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import arviz as az\n",
    "from line_profiler import LineProfiler\n",
    "from arviz.data import load_arviz_data\n",
    "from arviz.stats.stats import r2_score, hpd, _gpdfit, _gpinv\n",
    "import scipy.stats as st\n",
    "import numba\n",
    "import math\n",
    "from numpy import sin, cos\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = np.random.randn(10_000,1000)\n",
    "data_2 = np.random.randn(1_000_000)\n",
    "school = load_arviz_data(\"centered_eight\").posterior[\"mu\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'********************************************hpd********************************************************************'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''********************************************hpd********************************************************************'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 4.45015 s\n",
      "File: /opt/arviz/arviz/stats/stats.py\n",
      "Function: hpd at line 252\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   252                                           def hpd(ary, credible_interval=0.94, circular=False):\n",
      "   253                                               \"\"\"\n",
      "   254                                               Calculate highest posterior density (HPD) of array for given credible_interval.\n",
      "   255                                           \n",
      "   256                                               The HPD is the minimum width Bayesian credible interval (BCI). This implementation works only\n",
      "   257                                               for unimodal distributions.\n",
      "   258                                           \n",
      "   259                                               Parameters\n",
      "   260                                               ----------\n",
      "   261                                               x : Numpy array\n",
      "   262                                                   An array containing posterior samples\n",
      "   263                                               credible_interval : float, optional\n",
      "   264                                                   Credible interval to compute. Defaults to 0.94.\n",
      "   265                                               circular : bool, optional\n",
      "   266                                                   Whether to compute the hpd taking into account `x` is a circular variable\n",
      "   267                                                   (in the range [-np.pi, np.pi]) or not. Defaults to False (i.e non-circular variables).\n",
      "   268                                           \n",
      "   269                                               Returns\n",
      "   270                                               -------\n",
      "   271                                               np.ndarray\n",
      "   272                                                   lower and upper value of the interval.\n",
      "   273                                               \"\"\"\n",
      "   274      1001       4171.0      4.2      0.1      if ary.ndim > 1:\n",
      "   275         1          6.0      6.0      0.0          hpd_array = np.array(\n",
      "   276         1         23.0     23.0      0.0              [hpd(row, credible_interval=credible_interval, circular=circular) for row in ary.T]\n",
      "   277                                                   )\n",
      "   278         1          4.0      4.0      0.0          return hpd_array\n",
      "   279                                               # Make a copy of trace\n",
      "   280      1000     224684.0    224.7      5.0      ary = ary.copy()\n",
      "   281      1000       4797.0      4.8      0.1      n = len(ary)\n",
      "   282                                           \n",
      "   283      1000       2743.0      2.7      0.1      if circular:\n",
      "   284      1000    1439961.0   1440.0     32.4          mean = st.circmean(ary, high=np.pi, low=-np.pi)\n",
      "   285      1000      27534.0     27.5      0.6          ary = ary - mean\n",
      "   286      1000    1605540.0   1605.5     36.1          ary = np.arctan2(np.sin(ary), np.cos(ary))\n",
      "   287                                           \n",
      "   288      1000     985069.0    985.1     22.1      ary = np.sort(ary)\n",
      "   289      1000      24322.0     24.3      0.5      interval_idx_inc = int(np.floor(credible_interval * n))\n",
      "   290      1000       3780.0      3.8      0.1      n_intervals = n - interval_idx_inc\n",
      "   291      1000      17025.0     17.0      0.4      interval_width = ary[interval_idx_inc:] - ary[:n_intervals]\n",
      "   292                                           \n",
      "   293      1000       5056.0      5.1      0.1      if len(interval_width) == 0:\n",
      "   294                                                   raise ValueError(\n",
      "   295                                                       \"Too few elements for interval calculation. \"\n",
      "   296                                                       \"Check that credible_interval meets condition 0 =< credible_interval < 1\"\n",
      "   297                                                   )\n",
      "   298                                           \n",
      "   299      1000      25735.0     25.7      0.6      min_idx = np.argmin(interval_width)\n",
      "   300      1000       4984.0      5.0      0.1      hdi_min = ary[min_idx]\n",
      "   301      1000       5666.0      5.7      0.1      hdi_max = ary[min_idx + interval_idx_inc]\n",
      "   302                                           \n",
      "   303      1000       2870.0      2.9      0.1      if circular:\n",
      "   304      1000       3498.0      3.5      0.1          hdi_min = hdi_min + mean\n",
      "   305      1000       2984.0      3.0      0.1          hdi_max = hdi_max + mean\n",
      "   306      1000      28702.0     28.7      0.6          hdi_min = np.arctan2(np.sin(hdi_min), np.cos(hdi_min))\n",
      "   307      1000      17132.0     17.1      0.4          hdi_max = np.arctan2(np.sin(hdi_max), np.cos(hdi_max))\n",
      "   308                                           \n",
      "   309      1000      13860.0     13.9      0.3      return np.array([hdi_min, hdi_max])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(hpd)\n",
    "wrapper(data_1, 0.94, True)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.476394 s\n",
      "File: /opt/arviz/arviz/stats/stats.py\n",
      "Function: hpd at line 252\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   252                                           def hpd(ary, credible_interval=0.94, circular=False):\n",
      "   253                                               \"\"\"\n",
      "   254                                               Calculate highest posterior density (HPD) of array for given credible_interval.\n",
      "   255                                           \n",
      "   256                                               The HPD is the minimum width Bayesian credible interval (BCI). This implementation works only\n",
      "   257                                               for unimodal distributions.\n",
      "   258                                           \n",
      "   259                                               Parameters\n",
      "   260                                               ----------\n",
      "   261                                               x : Numpy array\n",
      "   262                                                   An array containing posterior samples\n",
      "   263                                               credible_interval : float, optional\n",
      "   264                                                   Credible interval to compute. Defaults to 0.94.\n",
      "   265                                               circular : bool, optional\n",
      "   266                                                   Whether to compute the hpd taking into account `x` is a circular variable\n",
      "   267                                                   (in the range [-np.pi, np.pi]) or not. Defaults to False (i.e non-circular variables).\n",
      "   268                                           \n",
      "   269                                               Returns\n",
      "   270                                               -------\n",
      "   271                                               np.ndarray\n",
      "   272                                                   lower and upper value of the interval.\n",
      "   273                                               \"\"\"\n",
      "   274         1          8.0      8.0      0.0      if ary.ndim > 1:\n",
      "   275                                                   hpd_array = np.array(\n",
      "   276                                                       [hpd(row, credible_interval=credible_interval, circular=circular) for row in ary.T]\n",
      "   277                                                   )\n",
      "   278                                                   return hpd_array\n",
      "   279                                               # Make a copy of trace\n",
      "   280         1       8334.0   8334.0      1.7      ary = ary.copy()\n",
      "   281         1          8.0      8.0      0.0      n = len(ary)\n",
      "   282                                           \n",
      "   283         1          4.0      4.0      0.0      if circular:\n",
      "   284         1     148422.0 148422.0     31.2          mean = st.circmean(ary, high=np.pi, low=-np.pi)\n",
      "   285         1       2986.0   2986.0      0.6          ary = ary - mean\n",
      "   286         1     168611.0 168611.0     35.4          ary = np.arctan2(np.sin(ary), np.cos(ary))\n",
      "   287                                           \n",
      "   288         1     145869.0 145869.0     30.6      ary = np.sort(ary)\n",
      "   289         1         70.0     70.0      0.0      interval_idx_inc = int(np.floor(credible_interval * n))\n",
      "   290         1          5.0      5.0      0.0      n_intervals = n - interval_idx_inc\n",
      "   291         1       1152.0   1152.0      0.2      interval_width = ary[interval_idx_inc:] - ary[:n_intervals]\n",
      "   292                                           \n",
      "   293         1         31.0     31.0      0.0      if len(interval_width) == 0:\n",
      "   294                                                   raise ValueError(\n",
      "   295                                                       \"Too few elements for interval calculation. \"\n",
      "   296                                                       \"Check that credible_interval meets condition 0 =< credible_interval < 1\"\n",
      "   297                                                   )\n",
      "   298                                           \n",
      "   299         1        739.0    739.0      0.2      min_idx = np.argmin(interval_width)\n",
      "   300         1         12.0     12.0      0.0      hdi_min = ary[min_idx]\n",
      "   301         1         13.0     13.0      0.0      hdi_max = ary[min_idx + interval_idx_inc]\n",
      "   302                                           \n",
      "   303         1          3.0      3.0      0.0      if circular:\n",
      "   304         1          4.0      4.0      0.0          hdi_min = hdi_min + mean\n",
      "   305         1          4.0      4.0      0.0          hdi_max = hdi_max + mean\n",
      "   306         1         60.0     60.0      0.0          hdi_min = np.arctan2(np.sin(hdi_min), np.cos(hdi_min))\n",
      "   307         1         40.0     40.0      0.0          hdi_max = np.arctan2(np.sin(hdi_max), np.cos(hdi_max))\n",
      "   308                                           \n",
      "   309         1         19.0     19.0      0.0      return np.array([hdi_min, hdi_max])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(hpd)\n",
    "wrapper(data_2, 0.94, True)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.109487 s\n",
      "File: /opt/arviz/arviz/stats/stats.py\n",
      "Function: hpd at line 252\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   252                                           def hpd(ary, credible_interval=0.94, circular=False):\n",
      "   253                                               \"\"\"\n",
      "   254                                               Calculate highest posterior density (HPD) of array for given credible_interval.\n",
      "   255                                           \n",
      "   256                                               The HPD is the minimum width Bayesian credible interval (BCI). This implementation works only\n",
      "   257                                               for unimodal distributions.\n",
      "   258                                           \n",
      "   259                                               Parameters\n",
      "   260                                               ----------\n",
      "   261                                               x : Numpy array\n",
      "   262                                                   An array containing posterior samples\n",
      "   263                                               credible_interval : float, optional\n",
      "   264                                                   Credible interval to compute. Defaults to 0.94.\n",
      "   265                                               circular : bool, optional\n",
      "   266                                                   Whether to compute the hpd taking into account `x` is a circular variable\n",
      "   267                                                   (in the range [-np.pi, np.pi]) or not. Defaults to False (i.e non-circular variables).\n",
      "   268                                           \n",
      "   269                                               Returns\n",
      "   270                                               -------\n",
      "   271                                               np.ndarray\n",
      "   272                                                   lower and upper value of the interval.\n",
      "   273                                               \"\"\"\n",
      "   274       501       1602.0      3.2      1.5      if ary.ndim > 1:\n",
      "   275         1          4.0      4.0      0.0          hpd_array = np.array(\n",
      "   276         1         14.0     14.0      0.0              [hpd(row, credible_interval=credible_interval, circular=circular) for row in ary.T]\n",
      "   277                                                   )\n",
      "   278         1          3.0      3.0      0.0          return hpd_array\n",
      "   279                                               # Make a copy of trace\n",
      "   280       500       2835.0      5.7      2.6      ary = ary.copy()\n",
      "   281       500       1511.0      3.0      1.4      n = len(ary)\n",
      "   282                                           \n",
      "   283       500       1229.0      2.5      1.1      if circular:\n",
      "   284       500      36330.0     72.7     33.2          mean = st.circmean(ary, high=np.pi, low=-np.pi)\n",
      "   285       500       4125.0      8.2      3.8          ary = ary - mean\n",
      "   286       500       4737.0      9.5      4.3          ary = np.arctan2(np.sin(ary), np.cos(ary))\n",
      "   287                                           \n",
      "   288       500      11018.0     22.0     10.1      ary = np.sort(ary)\n",
      "   289       500       4396.0      8.8      4.0      interval_idx_inc = int(np.floor(credible_interval * n))\n",
      "   290       500       1455.0      2.9      1.3      n_intervals = n - interval_idx_inc\n",
      "   291       500       3581.0      7.2      3.3      interval_width = ary[interval_idx_inc:] - ary[:n_intervals]\n",
      "   292                                           \n",
      "   293       500       1576.0      3.2      1.4      if len(interval_width) == 0:\n",
      "   294                                                   raise ValueError(\n",
      "   295                                                       \"Too few elements for interval calculation. \"\n",
      "   296                                                       \"Check that credible_interval meets condition 0 =< credible_interval < 1\"\n",
      "   297                                                   )\n",
      "   298                                           \n",
      "   299       500       6589.0     13.2      6.0      min_idx = np.argmin(interval_width)\n",
      "   300       500       1764.0      3.5      1.6      hdi_min = ary[min_idx]\n",
      "   301       500       2015.0      4.0      1.8      hdi_max = ary[min_idx + interval_idx_inc]\n",
      "   302                                           \n",
      "   303       500       1260.0      2.5      1.2      if circular:\n",
      "   304       500       1490.0      3.0      1.4          hdi_min = hdi_min + mean\n",
      "   305       500       1392.0      2.8      1.3          hdi_max = hdi_max + mean\n",
      "   306       500       9021.0     18.0      8.2          hdi_min = np.arctan2(np.sin(hdi_min), np.cos(hdi_min))\n",
      "   307       500       7489.0     15.0      6.8          hdi_max = np.arctan2(np.sin(hdi_max), np.cos(hdi_max))\n",
      "   308                                           \n",
      "   309       500       4051.0      8.1      3.7      return np.array([hdi_min, hdi_max])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(hpd)\n",
    "wrapper(school, 0.94, True)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBottlenecks:\\n    1)scipy.stats.circmean\\n    2)numpy arctan2\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Bottlenecks:\n",
    "    1)scipy.stats.circmean\n",
    "    2)numpy arctan2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _circ_mean(ary, high, low):\n",
    "    ary = np.asarray(ary)\n",
    "    if ary.size==0:\n",
    "        return np.nan, np.nan\n",
    "    pi = np.pi\n",
    "    angles = (ary-low)*2*pi/(high-low)\n",
    "    S = sinusoidal(angles)\n",
    "    C = cosine(angles)\n",
    "    res = np.arctan2(S,C)\n",
    "    mask = res < 0\n",
    "    if mask.ndim > 0:\n",
    "        res[mask] += 2*pi\n",
    "    elif mask:\n",
    "        res += 2*pi\n",
    "    return res*(high - low)/2.0/pi + low\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def sinusoidal(x):\n",
    "    summ = 0\n",
    "    x = x.flatten()\n",
    "    for i in range(0,len(x)):\n",
    "        summ = summ+math.sin(x[i])\n",
    "    return summ\n",
    "@numba.jit(nopython=True)\n",
    "def cosine(x):\n",
    "    summ = 0\n",
    "    x = x.flatten()\n",
    "    for i in range(0,len(x)):\n",
    "        summ = summ+math.cos(x[i])\n",
    "    return summ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434 ms ± 5.78 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sinusoidal(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 ms ± 3.57 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.sin(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.3 ms ± 596 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sinusoidal(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.9 ms ± 362 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.sin(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463 ms ± 2.55 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cosine(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 ms ± 6.27 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.cos(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.2 ms ± 708 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cosine(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.3 ms ± 1.83 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.cos(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_circ_mean(data_1, np.pi, -np.pi), st.circmean(data_1, np.pi, -np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_circ_mean(data_2, np.pi, -np.pi), st.circmean(data_2, np.pi, -np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_circ_mean(school, np.pi, -np.pi), st.circmean(school, np.pi, -np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.72 s ± 80.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _circ_mean(data_1, np.pi, -np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.64 s ± 94.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit st.circmean(data_1, np.pi, -np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 ms ± 8.34 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _circ_mean(data_2, np.pi, -np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 ms ± 1.94 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit st.circmean(data_2, np.pi, -np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 µs ± 22.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _circ_mean(school, np.pi, -np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 µs ± 15.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit st.circmean(school, np.pi, -np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Performance after numba is just as good as the original circmean on large datasets and it is a bit unstable.\\n   On schools, the performance is much better.\\n   ¯\\\\_(ツ)_/¯\\n   Let's see the overall perfomance of hpd\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Performance after numba is just as good as the original circmean on large datasets and it is a bit unstable.\n",
    "   On schools, the performance is much better.\n",
    "   ¯\\_(ツ)_/¯\n",
    "   Let's see the overall perfomance of hpd\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpd(ary, credible_interval=0.94, circular=False):\n",
    "    if ary.ndim > 1:\n",
    "        hpd_array = np.array(\n",
    "            [hpd(row, credible_interval=credible_interval, circular=circular) for row in ary.T]\n",
    "        )\n",
    "        return hpd_array\n",
    "    # Make a copy of trace\n",
    "    ary = ary.copy()\n",
    "    n = len(ary)\n",
    "\n",
    "    if circular:\n",
    "        mean = _circ_mean(ary, high=np.pi, low=-np.pi)\n",
    "        ary = ary - mean\n",
    "        ary = np.arctan2(np.sin(ary), np.cos(ary))\n",
    "\n",
    "    ary = np.sort(ary)\n",
    "    interval_idx_inc = int(np.floor(credible_interval * n))\n",
    "    n_intervals = n - interval_idx_inc\n",
    "    interval_width = ary[interval_idx_inc:] - ary[:n_intervals]\n",
    "\n",
    "    if len(interval_width) == 0:\n",
    "        raise ValueError(\n",
    "            \"Too few elements for interval calculation. \"\n",
    "            \"Check that credible_interval meets condition 0 =< credible_interval < 1\"\n",
    "        )\n",
    "\n",
    "    min_idx = np.argmin(interval_width)\n",
    "    hdi_min = ary[min_idx]\n",
    "    hdi_max = ary[min_idx + interval_idx_inc]\n",
    "\n",
    "    if circular:\n",
    "        hdi_min = hdi_min + mean\n",
    "        hdi_max = hdi_max + mean\n",
    "        hdi_min = np.arctan2(np.sin(hdi_min), np.cos(hdi_min))\n",
    "        hdi_max = np.arctan2(np.sin(hdi_max), np.cos(hdi_max))\n",
    "\n",
    "    return np.array([hdi_min, hdi_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(hpd(school, 0.95,True), az.stats.hpd(school, 0.95,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(hpd(data_1, 0.95,True), az.stats.hpd(data_1, 0.95,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(hpd(data_2, 0.95,True), az.stats.hpd(data_2, 0.95,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.9 ms ± 2.78 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hpd(school, 0.95,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.9 ms ± 3.26 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.hpd(school, 0.95,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.07 s ± 227 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hpd(data_1, 0.95,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.37 s ± 102 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.hpd(data_1, 0.95,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482 ms ± 17.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hpd(data_2, 0.95,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491 ms ± 38.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.hpd(data_2, 0.95,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As seen above, the performance of numba is better with school dataset.\\nThe performance with large datasets is a bit unstable.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''As seen above, the performance of numba is better with school dataset.\n",
    "The performance with large datasets is a bit unstable.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'******************************************R2_SCORE***************************************************************'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''******************************************R2_SCORE***************************************************************'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = np.random.randn(1000,1000)\n",
    "data_2 = np.random.randn(1_000_000)\n",
    "data_3 = np.random.randn(1000,1000)\n",
    "data_4 = np.random.randn(1_000_000)\n",
    "school = load_arviz_data(\"centered_eight\").posterior[\"mu\"].values\n",
    "n_school = load_arviz_data(\"non_centered_eight\").posterior[\"mu\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.053003 s\n",
      "File: /opt/arviz/arviz/stats/stats.py\n",
      "Function: r2_score at line 568\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   568                                           def r2_score(y_true, y_pred):\n",
      "   569                                               \"\"\"R² for Bayesian regression models. Only valid for linear models.\n",
      "   570                                           \n",
      "   571                                               Parameters\n",
      "   572                                               ----------\n",
      "   573                                               y_true: : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "   574                                                   Ground truth (correct) target values.\n",
      "   575                                               y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "   576                                                   Estimated target values.\n",
      "   577                                           \n",
      "   578                                               Returns\n",
      "   579                                               -------\n",
      "   580                                               Pandas Series with the following indices:\n",
      "   581                                               r2: Bayesian R²\n",
      "   582                                               r2_std: standard deviation of the Bayesian R².\n",
      "   583                                               \"\"\"\n",
      "   584         1          5.0      5.0      0.0      if y_pred.ndim == 1:\n",
      "   585                                                   var_y_est = np.var(y_pred)\n",
      "   586                                                   var_e = np.var(y_true - y_pred)\n",
      "   587                                               else:\n",
      "   588         1       2300.0   2300.0      4.3          var_y_est = np.var(y_pred.mean(0))\n",
      "   589         1      23314.0  23314.0     44.0          var_e = np.var(y_true - y_pred, 0)\n",
      "   590                                           \n",
      "   591         1         44.0     44.0      0.1      r_squared = var_y_est / (var_y_est + var_e)\n",
      "   592                                           \n",
      "   593         1      27340.0  27340.0     51.6      return pd.Series([np.mean(r_squared), np.std(r_squared)], index=[\"r2\", \"r2_std\"])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(r2_score)\n",
    "wrapper(data_1, data_3)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.030574 s\n",
      "File: /opt/arviz/arviz/stats/stats.py\n",
      "Function: r2_score at line 568\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   568                                           def r2_score(y_true, y_pred):\n",
      "   569                                               \"\"\"R² for Bayesian regression models. Only valid for linear models.\n",
      "   570                                           \n",
      "   571                                               Parameters\n",
      "   572                                               ----------\n",
      "   573                                               y_true: : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "   574                                                   Ground truth (correct) target values.\n",
      "   575                                               y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
      "   576                                                   Estimated target values.\n",
      "   577                                           \n",
      "   578                                               Returns\n",
      "   579                                               -------\n",
      "   580                                               Pandas Series with the following indices:\n",
      "   581                                               r2: Bayesian R²\n",
      "   582                                               r2_std: standard deviation of the Bayesian R².\n",
      "   583                                               \"\"\"\n",
      "   584         1          7.0      7.0      0.0      if y_pred.ndim == 1:\n",
      "   585         1      10471.0  10471.0     34.2          var_y_est = np.var(y_pred)\n",
      "   586         1      17603.0  17603.0     57.6          var_e = np.var(y_true - y_pred)\n",
      "   587                                               else:\n",
      "   588                                                   var_y_est = np.var(y_pred.mean(0))\n",
      "   589                                                   var_e = np.var(y_true - y_pred, 0)\n",
      "   590                                           \n",
      "   591         1         12.0     12.0      0.0      r_squared = var_y_est / (var_y_est + var_e)\n",
      "   592                                           \n",
      "   593         1       2481.0   2481.0      8.1      return pd.Series([np.mean(r_squared), np.std(r_squared)], index=[\"r2\", \"r2_std\"])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(r2_score)\n",
    "wrapper(data_2, data_4)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def _var_1d(data):\n",
    "    a,b = 0,0\n",
    "    for i in data:\n",
    "        a = a+i\n",
    "        b = b+i*i\n",
    "    return b/len(data)-((a/len(data))**2)\n",
    "\n",
    "@numba.jit\n",
    "def _var_2d(data):\n",
    "    a,b = data.shape\n",
    "    var = np.zeros(b)\n",
    "    for i in range(0,b):\n",
    "        var[i] = _var_1d(data[:,i])\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0001861022879104"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_var_1d(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0001861022879106"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_var_1d(data_2), np.var(data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_var_1d(data_4), np.var(data_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.01 ms ± 373 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _var_1d(data_2-data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.1 ms ± 1.26 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.var(data_2-data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_var_1d(data_2-data_4),np.var(data_2-data_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.3 µs ± 10.8 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _var_2d(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.6 µs ± 3.11 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.var(school,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.28 ms ± 95.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _var_2d(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.2 ms ± 1.31 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.var(data_1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.36 ms ± 774 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _var_2d(data_3-data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.3 ms ± 2.82 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.var(data_3-data_1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_var_2d(school), np.var(school,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_var_2d(data_1), np.var(data_1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_var_2d(data_3), np.var(data_3,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_var_2d(data_3-data_1), np.var(data_3-data_1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_var_2d(data_1-data_3), np.var(data_1-data_3,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Numba is doing wonders with variance. Lets inspect mean'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Numba is doing wonders with variance. Lets inspect mean'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def mean_1d(data):\n",
    "    summ = 0\n",
    "    for i in data:\n",
    "        summ = summ+i\n",
    "    return summ/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006988608470254329"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_1d(data_2-data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006988608470254803"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data_2-data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.46 ms ± 341 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mean_1d(data_2-data_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.89 ms ± 551 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.mean(data_2-data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Numba is not suitable here. Lets see the overall r2_score performance'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Numba is not suitable here. Lets see the overall r2_score performance'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_true, y_pred):\n",
    "    if y_pred.ndim == 1:\n",
    "        var_y_est = _var_1d(y_pred)\n",
    "        var_e = _var_1d(y_true - y_pred)\n",
    "    else:\n",
    "        var_y_est = _var_1d(y_pred.mean(0))\n",
    "        var_e = _var_2d(y_true - y_pred)\n",
    "\n",
    "    r_squared = var_y_est / (var_y_est + var_e)\n",
    "\n",
    "    return pd.Series([np.mean(r_squared), np.std(r_squared)], index=[\"r2\", \"r2_std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.23 ms ± 718 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit r2_score(data_2, data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.3 ms ± 1.69 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.r2_score(data_2, data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.16 ms ± 443 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit r2_score(data_1, data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.4 ms ± 726 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.r2_score(data_1, data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 ms ± 108 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit r2_score(school, n_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 ms ± 193 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.r2_score(school, n_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = r2_score(school, n_school)\n",
    "df_2 = az.stats.r2_score(school, n_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r2        0.219553\n",
       "r2_std    0.168670\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r2        0.219553\n",
       "r2_std    0.168670\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r2        False\n",
       "r2_std    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1==df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r2        0.000518\n",
       "r2_std    0.000023\n",
       "dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(data_1, data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r2        0.000518\n",
       "r2_std    0.000023\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.stats.r2_score(data_1, data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have not included the pandas test yet...will include them soon'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''I have not included the pandas test yet...will include them soon'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It can be clearly seen that numba greatly improves the performance of r2_score.\\nTBH, this was the function which I thought had the least scope of improvement\\nThank you mentors.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''It can be clearly seen that numba greatly improves the performance of r2_score.\n",
    "TBH, this was the function which I thought had the least scope of improvement\n",
    "Thank you mentors.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_gpdfit'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"_gpdfit\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.abs(np.sort(np.random.randn(100000)))\n",
    "school = np.abs(np.sort((load_arviz_data(\"centered_eight\").posterior[\"mu\"].values)[1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/arviz/arviz/stats/stats.py:520: RuntimeWarning: overflow encountered in exp\n",
      "  weights = 1 / np.exp(len_scale - len_scale[:, None]).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 4.64491 s\n",
      "File: /opt/arviz/arviz/stats/stats.py\n",
      "Function: _gpdfit at line 491\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   491                                           def _gpdfit(ary):\n",
      "   492                                               \"\"\"Estimate the parameters for the Generalized Pareto Distribution (GPD).\n",
      "   493                                           \n",
      "   494                                               Empirical Bayes estimate for the parameters of the generalized Pareto\n",
      "   495                                               distribution given the data.\n",
      "   496                                           \n",
      "   497                                               Parameters\n",
      "   498                                               ----------\n",
      "   499                                               ary : array\n",
      "   500                                                   sorted 1D data array\n",
      "   501                                           \n",
      "   502                                               Returns\n",
      "   503                                               -------\n",
      "   504                                               k : float\n",
      "   505                                                   estimated shape parameter\n",
      "   506                                               sigma : float\n",
      "   507                                                   estimated scale parameter\n",
      "   508                                               \"\"\"\n",
      "   509         1          4.0      4.0      0.0      prior_bs = 3\n",
      "   510         1          4.0      4.0      0.0      prior_k = 10\n",
      "   511         1          5.0      5.0      0.0      n = len(ary)\n",
      "   512         1         15.0     15.0      0.0      m_est = 30 + int(n ** 0.5)\n",
      "   513                                           \n",
      "   514         1        106.0    106.0      0.0      b_ary = 1 - np.sqrt(m_est / (np.arange(1, m_est + 1, dtype=float) - 0.5))\n",
      "   515         1         32.0     32.0      0.0      b_ary /= prior_bs * ary[int(n / 4 + 0.5) - 1]\n",
      "   516         1         12.0     12.0      0.0      b_ary += 1 / ary[-1]\n",
      "   517                                           \n",
      "   518         1    4498979.0 4498979.0     96.9      k_ary = np.log1p(-b_ary[:, None] * ary).mean(axis=1)  # pylint: disable=no-member\n",
      "   519         1      37992.0  37992.0      0.8      len_scale = n * (np.log(-(b_ary / k_ary)) - k_ary - 1)\n",
      "   520         1      11954.0  11954.0      0.3      weights = 1 / np.exp(len_scale - len_scale[:, None]).sum(axis=1)\n",
      "   521                                           \n",
      "   522                                               # remove negligible weights\n",
      "   523         1         93.0     93.0      0.0      real_idxs = weights >= 10 * np.finfo(float).eps\n",
      "   524         1      91860.0  91860.0      2.0      if not np.all(real_idxs):\n",
      "   525         1         26.0     26.0      0.0          weights = weights[real_idxs]\n",
      "   526         1          7.0      7.0      0.0          b_ary = b_ary[real_idxs]\n",
      "   527                                               # normalise weights\n",
      "   528         1         92.0     92.0      0.0      weights /= weights.sum()\n",
      "   529                                           \n",
      "   530                                               # posterior mean for b\n",
      "   531         1         90.0     90.0      0.0      b_post = np.sum(b_ary * weights)\n",
      "   532                                               # estimate for k\n",
      "   533         1       3601.0   3601.0      0.1      k_post = np.log1p(-b_post * ary).mean()  # pylint: disable=invalid-unary-operand-type,no-member\n",
      "   534                                               # add prior for k_post\n",
      "   535         1         26.0     26.0      0.0      k_post = (n * k_post + prior_k * 0.5) / (n + prior_k)\n",
      "   536         1         10.0     10.0      0.0      sigma = -k_post / b_post\n",
      "   537                                           \n",
      "   538         1          6.0      6.0      0.0      return k_post, sigma\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(_gpdfit)\n",
    "wrapper(data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.002371 s\n",
      "File: /opt/arviz/arviz/stats/stats.py\n",
      "Function: _gpdfit at line 491\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   491                                           def _gpdfit(ary):\n",
      "   492                                               \"\"\"Estimate the parameters for the Generalized Pareto Distribution (GPD).\n",
      "   493                                           \n",
      "   494                                               Empirical Bayes estimate for the parameters of the generalized Pareto\n",
      "   495                                               distribution given the data.\n",
      "   496                                           \n",
      "   497                                               Parameters\n",
      "   498                                               ----------\n",
      "   499                                               ary : array\n",
      "   500                                                   sorted 1D data array\n",
      "   501                                           \n",
      "   502                                               Returns\n",
      "   503                                               -------\n",
      "   504                                               k : float\n",
      "   505                                                   estimated shape parameter\n",
      "   506                                               sigma : float\n",
      "   507                                                   estimated scale parameter\n",
      "   508                                               \"\"\"\n",
      "   509         1          5.0      5.0      0.2      prior_bs = 3\n",
      "   510         1          3.0      3.0      0.1      prior_k = 10\n",
      "   511         1          5.0      5.0      0.2      n = len(ary)\n",
      "   512         1         13.0     13.0      0.5      m_est = 30 + int(n ** 0.5)\n",
      "   513                                           \n",
      "   514         1        119.0    119.0      5.0      b_ary = 1 - np.sqrt(m_est / (np.arange(1, m_est + 1, dtype=float) - 0.5))\n",
      "   515         1         43.0     43.0      1.8      b_ary /= prior_bs * ary[int(n / 4 + 0.5) - 1]\n",
      "   516         1         28.0     28.0      1.2      b_ary += 1 / ary[-1]\n",
      "   517                                           \n",
      "   518         1       1616.0   1616.0     68.2      k_ary = np.log1p(-b_ary[:, None] * ary).mean(axis=1)  # pylint: disable=no-member\n",
      "   519         1         59.0     59.0      2.5      len_scale = n * (np.log(-(b_ary / k_ary)) - k_ary - 1)\n",
      "   520         1        250.0    250.0     10.5      weights = 1 / np.exp(len_scale - len_scale[:, None]).sum(axis=1)\n",
      "   521                                           \n",
      "   522                                               # remove negligible weights\n",
      "   523         1         33.0     33.0      1.4      real_idxs = weights >= 10 * np.finfo(float).eps\n",
      "   524         1         35.0     35.0      1.5      if not np.all(real_idxs):\n",
      "   525         1          8.0      8.0      0.3          weights = weights[real_idxs]\n",
      "   526         1          4.0      4.0      0.2          b_ary = b_ary[real_idxs]\n",
      "   527                                               # normalise weights\n",
      "   528         1         24.0     24.0      1.0      weights /= weights.sum()\n",
      "   529                                           \n",
      "   530                                               # posterior mean for b\n",
      "   531         1         35.0     35.0      1.5      b_post = np.sum(b_ary * weights)\n",
      "   532                                               # estimate for k\n",
      "   533         1         80.0     80.0      3.4      k_post = np.log1p(-b_post * ary).mean()  # pylint: disable=invalid-unary-operand-type,no-member\n",
      "   534                                               # add prior for k_post\n",
      "   535         1          6.0      6.0      0.3      k_post = (n * k_post + prior_k * 0.5) / (n + prior_k)\n",
      "   536         1          3.0      3.0      0.1      sigma = -k_post / b_post\n",
      "   537                                           \n",
      "   538         1          2.0      2.0      0.1      return k_post, sigma\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(_gpdfit)\n",
    "wrapper(school)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bottleneck at 518'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Bottleneck at 518\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def log_1p(data):\n",
    "    log_p = np.zeros_like(data)\n",
    "    for i in range(0,len(data)):\n",
    "        log_p[i] = math.log1p(data[i])\n",
    "    return log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(log_1p(data), np.log1p(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(log_1p(school), np.log1p(school))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.28 ms ± 198 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit log_1p(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16 ms ± 312 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.log1p(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.4 µs ± 787 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit log_1p(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.7 µs ± 1.47 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.log1p(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Performance is somewhat unstable, almost half the time it speeds up the process, sometimes its performance is\\nwhile in 10% of trials the performance comes down a notch w.r.t to numpy'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Performance is somewhat unstable, almost half the time it speeds up the process, sometimes its performance is\n",
    "while in 10% of trials the performance comes down a notch w.r.t to numpy'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'overall performance of gpdfit'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''overall performance of gpdfit'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gpdfit(ary):\n",
    "    prior_bs = 3\n",
    "    prior_k = 10\n",
    "    n = len(ary)\n",
    "    m_est = 30 + int(n ** 0.5)\n",
    "\n",
    "    b_ary = 1 - np.sqrt(m_est / (np.arange(1, m_est + 1, dtype=float) - 0.5))\n",
    "    b_ary /= prior_bs * ary[int(n / 4 + 0.5) - 1]\n",
    "    b_ary += 1 / ary[-1]\n",
    "\n",
    "    k_ary = np.log1p(-b_ary[:, None] * ary).mean(axis=1) # pylint: disable=no-member Using my own log_1p here throws an exception\n",
    "    len_scale = n * (np.log(-(b_ary / k_ary)) - k_ary - 1)\n",
    "    weights = 1 / np.exp(len_scale - len_scale[:, None]).sum(axis=1)\n",
    "\n",
    "    # remove negligible weights\n",
    "    real_idxs = weights >= 10 * np.finfo(float).eps\n",
    "    if not np.all(real_idxs):\n",
    "        weights = weights[real_idxs]\n",
    "        b_ary = b_ary[real_idxs]\n",
    "    # normalise weights\n",
    "    weights /= weights.sum()\n",
    "\n",
    "    # posterior mean for b\n",
    "    b_post = np.sum(b_ary * weights)\n",
    "    # estimate for k\n",
    "    k_post = log_1p(-b_post * ary).mean()  # pylint: disable=invalid-unary-operand-type,no-member\n",
    "    # add prior for k_post\n",
    "    k_post = (n * k_post + prior_k * 0.5) / (n + prior_k)\n",
    "    sigma = -k_post / b_post\n",
    "    return k_post, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in exp\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.09 s ± 84.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _gpdfit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/arviz/arviz/stats/stats.py:520: RuntimeWarning: overflow encountered in exp\n",
      "  weights = 1 / np.exp(len_scale - len_scale[:, None]).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11 s ± 76.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.stats._gpdfit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882 µs ± 49.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _gpdfit(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870 µs ± 57.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.stats._gpdfit(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Similar performance on both the datasets. Up for discussion with mentors'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Similar performance on both the datasets. Up for discussion with mentors'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_gpvinv'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"_gpvinv\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(100000)\n",
    "school = load_arviz_data(\"centered_eight\").posterior[\"mu\"].values[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.043464 s\n",
      "File: /opt/arviz/arviz/stats/stats.py\n",
      "Function: _gpinv at line 541\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   541                                           def _gpinv(probs, kappa, sigma):\n",
      "   542                                               \"\"\"Inverse Generalized Pareto distribution function.\"\"\"\n",
      "   543                                               # pylint: disable=unsupported-assignment-operation, invalid-unary-operand-type\n",
      "   544         1        379.0    379.0      0.9      x = np.full_like(probs, np.nan)\n",
      "   545         1          4.0      4.0      0.0      if sigma <= 0:\n",
      "   546                                                   return x\n",
      "   547         1       1050.0   1050.0      2.4      ok = (probs > 0) & (probs < 1)\n",
      "   548         1         86.0     86.0      0.2      if np.all(ok):\n",
      "   549                                                   if np.abs(kappa) < np.finfo(float).eps:\n",
      "   550                                                       x = -np.log1p(-probs)\n",
      "   551                                                   else:\n",
      "   552                                                       x = np.expm1(-kappa * np.log1p(-probs)) / kappa\n",
      "   553                                                   x *= sigma\n",
      "   554                                               else:\n",
      "   555         1      35234.0  35234.0     81.1          if np.abs(kappa) < np.finfo(float).eps:\n",
      "   556                                                       x[ok] = -np.log1p(-probs[ok])\n",
      "   557                                                   else:\n",
      "   558         1       5153.0   5153.0     11.9              x[ok] = np.expm1(-kappa * np.log1p(-probs[ok])) / kappa\n",
      "   559         1        495.0    495.0      1.1          x *= sigma\n",
      "   560         1        662.0    662.0      1.5          x[probs == 0] = 0\n",
      "   561         1          6.0      6.0      0.0          if kappa >= 0:\n",
      "   562         1        393.0    393.0      0.9              x[probs == 1] = np.inf\n",
      "   563                                                   else:\n",
      "   564                                                       x[probs == 1] = -sigma / kappa\n",
      "   565         1          2.0      2.0      0.0      return x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(_gpinv)\n",
    "wrapper(data, 5,2)\n",
    "lp.print_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.000443 s\n",
      "File: /opt/arviz/arviz/stats/stats.py\n",
      "Function: _gpinv at line 541\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   541                                           def _gpinv(probs, kappa, sigma):\n",
      "   542                                               \"\"\"Inverse Generalized Pareto distribution function.\"\"\"\n",
      "   543                                               # pylint: disable=unsupported-assignment-operation, invalid-unary-operand-type\n",
      "   544         1         62.0     62.0     14.0      x = np.full_like(probs, np.nan)\n",
      "   545         1          5.0      5.0      1.1      if sigma <= 0:\n",
      "   546                                                   return x\n",
      "   547         1         55.0     55.0     12.4      ok = (probs > 0) & (probs < 1)\n",
      "   548         1         85.0     85.0     19.2      if np.all(ok):\n",
      "   549                                                   if np.abs(kappa) < np.finfo(float).eps:\n",
      "   550                                                       x = -np.log1p(-probs)\n",
      "   551                                                   else:\n",
      "   552                                                       x = np.expm1(-kappa * np.log1p(-probs)) / kappa\n",
      "   553                                                   x *= sigma\n",
      "   554                                               else:\n",
      "   555         1         69.0     69.0     15.6          if np.abs(kappa) < np.finfo(float).eps:\n",
      "   556                                                       x[ok] = -np.log1p(-probs[ok])\n",
      "   557                                                   else:\n",
      "   558         1        105.0    105.0     23.7              x[ok] = np.expm1(-kappa * np.log1p(-probs[ok])) / kappa\n",
      "   559         1         23.0     23.0      5.2          x *= sigma\n",
      "   560         1         18.0     18.0      4.1          x[probs == 0] = 0\n",
      "   561         1          4.0      4.0      0.9          if kappa >= 0:\n",
      "   562         1         14.0     14.0      3.2              x[probs == 1] = np.inf\n",
      "   563                                                   else:\n",
      "   564                                                       x[probs == 1] = -sigma / kappa\n",
      "   565         1          3.0      3.0      0.7      return x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(_gpinv)\n",
    "wrapper(school, 5,2)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Log1p or expm is the bottleneck again'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Log1p or expm is the bottleneck again'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def expm(data):\n",
    "    expm = np.zeros_like(data)\n",
    "    for i in range(0,len(data)):\n",
    "        expm[i] = math.expm1(data[i])\n",
    "    return expm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(expm(data), np.expm1(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.09 ms ± 196 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit expm(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.93 ms ± 138 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.expm1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 µs ± 536 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit expm(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.7 µs ± 523 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.expm1(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'numpy is a bit faster\\nLets see the overall performance'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''numpy is a bit faster\n",
    "Lets see the overall performance'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gpinv(probs, kappa, sigma):\n",
    "    \"\"\"Inverse Generalized Pareto distribution function.\"\"\"\n",
    "    # pylint: disable=unsupported-assignment-operation, invalid-unary-operand-type\n",
    "    x = np.full_like(probs, np.nan)\n",
    "    if sigma <= 0:\n",
    "        return x\n",
    "    ok = (probs > 0) & (probs < 1)\n",
    "    if np.all(ok):\n",
    "        if np.abs(kappa) < np.finfo(float).eps:\n",
    "            x = -log_1p(-probs)\n",
    "        else:\n",
    "            x = np.expm1(-kappa * np.log1p(-probs)) / kappa\n",
    "        x *= sigma\n",
    "    else:\n",
    "        if np.abs(kappa) < np.finfo(float).eps:\n",
    "            x[ok] = -log_1p(-probs[ok])\n",
    "        else:\n",
    "            x[ok] = np.expm1(-kappa * np.log1p(-probs[ok])) / kappa\n",
    "        x *= sigma\n",
    "        x[probs == 0] = 0\n",
    "        if kappa >= 0:\n",
    "            x[probs == 1] = np.inf\n",
    "        else:\n",
    "            x[probs == 1] = -sigma / kappa\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = _gpinv(data,-5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = az.stats.stats._gpinv(data, -5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39755694,        nan,        nan, ...,        nan, 0.29756074,\n",
       "              nan])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39755694,        nan,        nan, ...,        nan, 0.29756074,\n",
       "              nan])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., nan, nan, ..., nan,  0., nan])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.17 ms ± 481 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _gpinv(data, -5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.87 ms ± 489 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.stats._gpinv(data, -5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.6 µs ± 947 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _gpinv(school, -5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.5 µs ± 1.46 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.stats._gpinv(school, -5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'numba _gpinv is similar in performance'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''numba _gpinv is similar in performance'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
