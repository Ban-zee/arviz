{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arviz.data.base import generate_dims_coords\n",
    "from arviz.data import load_arviz_data\n",
    "from arviz.data.converters import convert_to_inference_data\n",
    "from line_profiler import LineProfiler\n",
    "import numpy as np\n",
    "from numpy import array, average, dot\n",
    "import numba\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "import warnings\n",
    "from arviz.plots.kdeplot import _fast_kde_2d as f2\n",
    "import numpy as np\n",
    "import pkg_resources\n",
    "import xarray as xr\n",
    "import timeit\n",
    "from scipy.signal import gaussian, convolve, convolve2d  # pylint: disable=no-name-in-module\n",
    "from scipy.sparse import coo_matrix\n",
    "from collections import OrderedDict\n",
    "from collections.abc import Sequence\n",
    "from copy import copy as ccopy, deepcopy\n",
    "from datetime import datetime\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.000579 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/data/base.py\n",
      "Function: generate_dims_coords at line 30\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    30                                           def generate_dims_coords(shape, var_name, dims=None, coords=None, default_dims=None):\n",
      "    31                                               \"\"\"Generate default dimensions and coordinates for a variable.\n",
      "    32                                           \n",
      "    33                                               Parameters\n",
      "    34                                               ----------\n",
      "    35                                               shape : tuple[int]\n",
      "    36                                                   Shape of the variable\n",
      "    37                                               var_name : str\n",
      "    38                                                   Name of the variable. Used in the default name, if necessary\n",
      "    39                                               dims : list\n",
      "    40                                                   List of dimensions for the variable\n",
      "    41                                               coords : dict[str] -> list[str]\n",
      "    42                                                   Map of dimensions to coordinates\n",
      "    43                                               default_dims : list[str]\n",
      "    44                                                   Dimensions that do not apply to the variable's shape\n",
      "    45                                           \n",
      "    46                                               Returns\n",
      "    47                                               -------\n",
      "    48                                               list[str]\n",
      "    49                                                   Default dims\n",
      "    50                                               dict[str] -> list[str]\n",
      "    51                                                   Default coords\n",
      "    52                                               \"\"\"\n",
      "    53         1          4.0      4.0      0.7      if default_dims is None:\n",
      "    54         1          3.0      3.0      0.5          default_dims = []\n",
      "    55         1          3.0      3.0      0.5      if dims is None:\n",
      "    56         1          2.0      2.0      0.3          dims = []\n",
      "    57         1          8.0      8.0      1.4      if len([dim for dim in dims if dim not in default_dims]) > len(shape):\n",
      "    58                                                   warnings.warn(\n",
      "    59                                                       (\n",
      "    60                                                           \"In variable {var_name}, there are \"\n",
      "    61                                                           + \"more dims ({dims_len}) given than exist ({shape_len}). \"\n",
      "    62                                                           + \"Passed array should have shape (chains, draws, *shape)\"\n",
      "    63                                                       ).format(var_name=var_name, dims_len=len(dims), shape_len=len(shape)),\n",
      "    64                                                       SyntaxWarning,\n",
      "    65                                                   )\n",
      "    66         1          2.0      2.0      0.3      if coords is None:\n",
      "    67         1          3.0      3.0      0.5          coords = {}\n",
      "    68                                           \n",
      "    69         1         77.0     77.0     13.3      coords = deepcopy(coords)\n",
      "    70         1         39.0     39.0      6.7      dims = deepcopy(dims)\n",
      "    71                                           \n",
      "    72         4         20.0      5.0      3.5      for idx, dim_len in enumerate(shape):\n",
      "    73         3         22.0      7.3      3.8          if (len(dims) < idx + 1) or (dims[idx] is None):\n",
      "    74         3         31.0     10.3      5.4              dim_name = \"{var_name}_dim_{idx}\".format(var_name=var_name, idx=idx)\n",
      "    75         3         15.0      5.0      2.6              if len(dims) < idx + 1:\n",
      "    76         3         11.0      3.7      1.9                  dims.append(dim_name)\n",
      "    77                                                       else:\n",
      "    78                                                           dims[idx] = dim_name\n",
      "    79         3         11.0      3.7      1.9          dim_name = dims[idx]\n",
      "    80         3         11.0      3.7      1.9          if dim_name not in coords:\n",
      "    81         3        271.0     90.3     46.8              coords[dim_name] = np.arange(dim_len)\n",
      "    82         1         42.0     42.0      7.3      coords = {key: coord for key, coord in coords.items() if any(key == dim for dim in dims)}\n",
      "    83         1          4.0      4.0      0.7      return dims, coords\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(generate_dims_coords)\n",
    "wrapper((500,600,80), 'x')\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def range_(x):\n",
    "    return np.arange(x)\n",
    "\n",
    "\n",
    "def range_jit(x):\n",
    "    return np.arange(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 16.34 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "3.92 µs ± 5.66 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit range_(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.46 µs ± 96.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit range_jit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dims_coords(shape, var_name, dims=None, coords=None, default_dims=None):\n",
    "    if default_dims is None:\n",
    "        default_dims = []\n",
    "    if dims is None:\n",
    "        dims = []\n",
    "    if len([dim for dim in dims if dim not in default_dims]) > len(shape):\n",
    "        warnings.warn(\n",
    "            (\n",
    "                \"In variable {var_name}, there are \"\n",
    "                + \"more dims ({dims_len}) given than exist ({shape_len}). \"\n",
    "                + \"Passed array should have shape (chains, draws, *shape)\"\n",
    "            ).format(var_name=var_name, dims_len=len(dims), shape_len=len(shape)),\n",
    "            SyntaxWarning,\n",
    "        )\n",
    "    if coords is None:\n",
    "        coords = {}\n",
    "\n",
    "    coords = deepcopy(coords)\n",
    "    dims = deepcopy(dims)\n",
    "\n",
    "    for idx, dim_len in enumerate(shape):\n",
    "        if (len(dims) < idx + 1) or (dims[idx] is None):\n",
    "            dim_name = \"{var_name}_dim_{idx}\".format(var_name=var_name, idx=idx)\n",
    "            if len(dims) < idx + 1:\n",
    "                dims.append(dim_name)\n",
    "            else:\n",
    "                dims[idx] = dim_name\n",
    "        dim_name = dims[idx]\n",
    "        if dim_name not in coords:\n",
    "            coords[dim_name] = np.arange(dim_len)\n",
    "    coords = {key: coord for key, coord in coords.items() if any(key == dim for dim in dims)}\n",
    "    return dims, coords\n",
    "\n",
    "\n",
    "\n",
    "def generate_dims_coords_jit(shape, var_name, dims=None, coords=None, default_dims=None):\n",
    "    if default_dims is None:\n",
    "        default_dims = []\n",
    "    if dims is None:\n",
    "        dims = []\n",
    "    if len([dim for dim in dims if dim not in default_dims]) > len(shape):\n",
    "        warnings.warn(\n",
    "            (\n",
    "                \"In variable {var_name}, there are \"\n",
    "                + \"more dims ({dims_len}) given than exist ({shape_len}). \"\n",
    "                + \"Passed array should have shape (chains, draws, *shape)\"\n",
    "            ).format(var_name=var_name, dims_len=len(dims), shape_len=len(shape)),\n",
    "            SyntaxWarning,\n",
    "        )\n",
    "    if coords is None:\n",
    "        coords = {}\n",
    "\n",
    "    coords = deepcopy(coords)\n",
    "    dims = deepcopy(dims)\n",
    "\n",
    "    for idx, dim_len in enumerate(shape):\n",
    "        if (len(dims) < idx + 1) or (dims[idx] is None):\n",
    "            dim_name = \"{var_name}_dim_{idx}\".format(var_name=var_name, idx=idx)\n",
    "            if len(dims) < idx + 1:\n",
    "                dims.append(dim_name)\n",
    "            else:\n",
    "                dims[idx] = dim_name\n",
    "        dim_name = dims[idx]\n",
    "        if dim_name not in coords:\n",
    "            coords[dim_name] = range_(dim_len)\n",
    "    coords = {key: coord for key, coord in coords.items() if any(key == dim for dim in dims)}\n",
    "    return dims, coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.6 µs ± 3.2 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit generate_dims_coords((10000,10000), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.8 µs ± 3.51 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit generate_dims_coords_jit((10000,10000), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 µs ± 1.33 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit generate_dims_coords((10,190), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 µs ± 1.04 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit generate_dims_coords_jit((10,190), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_data_array(ary, *, var_name=\"data\", coords=None, dims=None):\n",
    "    # manage and transform copies\n",
    "    default_dims = [\"chain\", \"draw\"]\n",
    "    ary = np.atleast_2d(ary)\n",
    "    n_chains, n_samples, *shape = ary.shape\n",
    "    if n_chains > n_samples:\n",
    "        warnings.warn(\n",
    "            \"More chains ({n_chains}) than draws ({n_samples}). \"\n",
    "            \"Passed array should have shape (chains, draws, *shape)\".format(\n",
    "                n_chains=n_chains, n_samples=n_samples\n",
    "            ),\n",
    "            SyntaxWarning,\n",
    "        )\n",
    "\n",
    "    dims, coords = generate_dims_coords(\n",
    "        shape, var_name, dims=dims, coords=coords, default_dims=default_dims\n",
    "    )\n",
    "\n",
    "    # reversed order for default dims: 'chain', 'draw'\n",
    "    if \"draw\" not in dims:\n",
    "        dims = [\"draw\"] + dims\n",
    "    if \"chain\" not in dims:\n",
    "        dims = [\"chain\"] + dims\n",
    "\n",
    "    if \"chain\" not in coords:\n",
    "        coords[\"chain\"] = np.arange(n_chains)\n",
    "    if \"draw\" not in coords:\n",
    "        coords[\"draw\"] = np.arange(n_samples)\n",
    "\n",
    "    # filter coords based on the dims\n",
    "    coords = {key: xr.IndexVariable((key,), data=coords[key]) for key in dims}\n",
    "    return xr.DataArray(ary, coords=coords, dims=dims)\n",
    "\n",
    "\n",
    "def numpy_to_data_array_jit(ary, *, var_name=\"data\", coords=None, dims=None):\n",
    "    # manage and transform copies\n",
    "    default_dims = [\"chain\", \"draw\"]\n",
    "    ary = np.atleast_2d(ary)\n",
    "    n_chains, n_samples, *shape = ary.shape\n",
    "    if n_chains > n_samples:\n",
    "        warnings.warn(\n",
    "            \"More chains ({n_chains}) than draws ({n_samples}). \"\n",
    "            \"Passed array should have shape (chains, draws, *shape)\".format(\n",
    "                n_chains=n_chains, n_samples=n_samples\n",
    "            ),\n",
    "            SyntaxWarning,\n",
    "        )\n",
    "\n",
    "    dims, coords = generate_dims_coords_jit(\n",
    "        shape, var_name, dims=dims, coords=coords, default_dims=default_dims\n",
    "    )\n",
    "\n",
    "    # reversed order for default dims: 'chain', 'draw'\n",
    "    if \"draw\" not in dims:\n",
    "        dims = [\"draw\"] + dims\n",
    "    if \"chain\" not in dims:\n",
    "        dims = [\"chain\"] + dims\n",
    "\n",
    "    if \"chain\" not in coords:\n",
    "        coords[\"chain\"] = range_(n_chains)\n",
    "    if \"draw\" not in coords:\n",
    "        coords[\"draw\"] = range_(n_samples)\n",
    "\n",
    "    # filter coords based on the dims\n",
    "    coords = {key: xr.IndexVariable((key,), data=coords[key]) for key in dims}\n",
    "    return xr.DataArray(ary, coords=coords, dims=dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(10000,100)\n",
    "linear = np.random.randn(1000000)\n",
    "small = np.random.randn(100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/banzee/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SyntaxWarning: More chains (10000) than draws (100). Passed array should have shape (chains, draws, *shape)\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472 µs ± 81.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit numpy_to_data_array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/banzee/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:46: SyntaxWarning: More chains (10000) than draws (100). Passed array should have shape (chains, draws, *shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409 µs ± 50 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit numpy_to_data_array_jit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.84 ms ± 256 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit numpy_to_data_array(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.03 ms ± 123 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit numpy_to_data_array_jit(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414 µs ± 67.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit numpy_to_data_array(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362 µs ± 35 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit numpy_to_data_array_jit(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Very Similar Performance. Up for reconsideration'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Very Similar Performance. Up for reconsideration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to dataset bottleneck ---> numpy_to_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Converters'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"Converters\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(10000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.004205 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/data/converters.py\n",
      "Function: convert_to_inference_data at line 16\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    16                                           def convert_to_inference_data(obj, *, group=\"posterior\", coords=None, dims=None, **kwargs):\n",
      "    17                                               r\"\"\"Convert a supported object to an InferenceData object.\n",
      "    18                                           \n",
      "    19                                               This function sends `obj` to the right conversion function. It is idempotent,\n",
      "    20                                               in that it will return arviz.InferenceData objects unchanged.\n",
      "    21                                           \n",
      "    22                                               Parameters\n",
      "    23                                               ----------\n",
      "    24                                               obj : dict, str, np.ndarray, xr.Dataset, pystan fit, pymc3 trace\n",
      "    25                                                   A supported object to convert to InferenceData:\n",
      "    26                                                       | InferenceData: returns unchanged\n",
      "    27                                                       | str: Attempts to load the cmdstan csv or netcdf dataset from disk\n",
      "    28                                                       | pystan fit: Automatically extracts data\n",
      "    29                                                       | cmdstanpy fit: Automatically extracts data\n",
      "    30                                                       | cmdstan csv-list: Automatically extracts data\n",
      "    31                                                       | pymc3 trace: Automatically extracts data\n",
      "    32                                                       | emcee sampler: Automatically extracts data\n",
      "    33                                                       | pyro MCMC: Automatically extracts data\n",
      "    34                                                       | xarray.Dataset: adds to InferenceData as only group\n",
      "    35                                                       | dict: creates an xarray dataset as the only group\n",
      "    36                                                       | numpy array: creates an xarray dataset as the only group, gives the\n",
      "    37                                                                    array an arbitrary name\n",
      "    38                                               group : str\n",
      "    39                                                   If `obj` is a dict or numpy array, assigns the resulting xarray\n",
      "    40                                                   dataset to this group. Default: \"posterior\".\n",
      "    41                                               coords : dict[str, iterable]\n",
      "    42                                                   A dictionary containing the values that are used as index. The key\n",
      "    43                                                   is the name of the dimension, the values are the index values.\n",
      "    44                                               dims : dict[str, List(str)]\n",
      "    45                                                   A mapping from variables to a list of coordinate names for the variable\n",
      "    46                                               kwargs\n",
      "    47                                                   Rest of the supported keyword arguments transferred to conversion function.\n",
      "    48                                           \n",
      "    49                                               Returns\n",
      "    50                                               -------\n",
      "    51                                               InferenceData\n",
      "    52                                               \"\"\"\n",
      "    53         1          6.0      6.0      0.1      kwargs[group] = obj\n",
      "    54         1          3.0      3.0      0.1      kwargs[\"coords\"] = coords\n",
      "    55         1          2.0      2.0      0.0      kwargs[\"dims\"] = dims\n",
      "    56                                           \n",
      "    57                                               # Cases that convert to InferenceData\n",
      "    58         1          3.0      3.0      0.1      if isinstance(obj, InferenceData):\n",
      "    59                                                   return obj\n",
      "    60         1          2.0      2.0      0.0      elif isinstance(obj, str):\n",
      "    61                                                   if obj.endswith(\".csv\"):\n",
      "    62                                                       if group == \"sample_stats\":\n",
      "    63                                                           kwargs[\"posterior\"] = kwargs.pop(group)\n",
      "    64                                                       elif group == \"sample_stats_prior\":\n",
      "    65                                                           kwargs[\"prior\"] = kwargs.pop(group)\n",
      "    66                                                       return from_cmdstan(**kwargs)\n",
      "    67                                                   else:\n",
      "    68                                                       return InferenceData.from_netcdf(obj)\n",
      "    69                                               elif (\n",
      "    70         1          5.0      5.0      0.1          obj.__class__.__name__ in {\"StanFit4Model\", \"RunSet\"}\n",
      "    71         1          5.0      5.0      0.1          or obj.__class__.__module__ == \"stan.fit\"\n",
      "    72                                               ):\n",
      "    73                                                   if group == \"sample_stats\":\n",
      "    74                                                       kwargs[\"posterior\"] = kwargs.pop(group)\n",
      "    75                                                   elif group == \"sample_stats_prior\":\n",
      "    76                                                       kwargs[\"prior\"] = kwargs.pop(group)\n",
      "    77                                                   if obj.__class__.__name__ == \"RunSet\":\n",
      "    78                                                       return from_cmdstanpy(**kwargs)\n",
      "    79                                                   else:  # pystan or pystan3\n",
      "    80                                                       return from_pystan(**kwargs)\n",
      "    81         1          3.0      3.0      0.1      elif obj.__class__.__name__ == \"MultiTrace\":  # ugly, but doesn't make PyMC3 a requirement\n",
      "    82                                                   return from_pymc3(trace=kwargs.pop(group), **kwargs)\n",
      "    83         1          2.0      2.0      0.0      elif obj.__class__.__name__ == \"EnsembleSampler\":  # ugly, but doesn't make emcee a requirement\n",
      "    84                                                   return from_emcee(sampler=kwargs.pop(group), **kwargs)\n",
      "    85         1          2.0      2.0      0.0      elif obj.__class__.__name__ == \"MCMC\" and obj.__class__.__module__.startswith(\"pyro\"):\n",
      "    86                                                   return from_pyro(posterior=kwargs.pop(group), **kwargs)\n",
      "    87                                           \n",
      "    88                                               # Cases that convert to xarray\n",
      "    89         1        164.0    164.0      3.9      if isinstance(obj, xr.Dataset):\n",
      "    90                                                   dataset = obj\n",
      "    91         1          3.0      3.0      0.1      elif isinstance(obj, dict):\n",
      "    92                                                   dataset = dict_to_dataset(obj, coords=coords, dims=dims)\n",
      "    93         1          4.0      4.0      0.1      elif isinstance(obj, np.ndarray):\n",
      "    94         1       3976.0   3976.0     94.6          dataset = dict_to_dataset({\"x\": obj}, coords=coords, dims=dims)\n",
      "    95                                               elif isinstance(obj, (list, tuple)) and isinstance(obj[0], str) and obj[0].endswith(\".csv\"):\n",
      "    96                                                   if group == \"sample_stats\":\n",
      "    97                                                       kwargs[\"posterior\"] = kwargs.pop(group)\n",
      "    98                                                   elif group == \"sample_stats_prior\":\n",
      "    99                                                       kwargs[\"prior\"] = kwargs.pop(group)\n",
      "   100                                                   return from_cmdstan(**kwargs)\n",
      "   101                                               else:\n",
      "   102                                                   allowable_types = (\n",
      "   103                                                       \"xarray dataset\",\n",
      "   104                                                       \"dict\",\n",
      "   105                                                       \"netcdf file\",\n",
      "   106                                                       \"numpy array\",\n",
      "   107                                                       \"pystan fit\",\n",
      "   108                                                       \"pymc3 trace\",\n",
      "   109                                                       \"emcee fit\",\n",
      "   110                                                       \"pyro mcmc fit\",\n",
      "   111                                                       \"cmdstan fit csv\",\n",
      "   112                                                       \"cmdstanpy fit\",\n",
      "   113                                                   )\n",
      "   114                                                   raise ValueError(\n",
      "   115                                                       \"Can only convert {} to InferenceData, not {}\".format(\n",
      "   116                                                           \", \".join(allowable_types), obj.__class__.__name__\n",
      "   117                                                       )\n",
      "   118                                                   )\n",
      "   119                                           \n",
      "   120         1         25.0     25.0      0.6      return InferenceData(**{group: dataset})\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/banzee/Desktop/arviz/arviz/data/base.py:124: SyntaxWarning: More chains (10000) than draws (100). Passed array should have shape (chains, draws, *shape)\n",
      "  SyntaxWarning,\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(convert_to_inference_data)\n",
    "wrapper(data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottleneck is dict to dataset. Refer above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"DATASETS.PY'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"DATASETS.PY\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to improve here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"io_dict\"\"'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"io_dict\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"'\"\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottleneck is dict to dataset. Refer above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"io_netcdf'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"io_netcdf\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bottlenecks---->Inference data and convert_to_inference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inference_data'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"Inference_data\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceData:\n",
    "    \"\"\"Container for accessing netCDF files using xarray.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initialize InferenceData object from keyword xarray datasets.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        InferenceData(posterior=posterior, prior=prior)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        kwargs :\n",
    "            Keyword arguments of xarray datasets\n",
    "        \"\"\"\n",
    "        self._groups = []\n",
    "        for key, dataset in kwargs.items():\n",
    "            if dataset is None:\n",
    "                continue\n",
    "            elif not isinstance(dataset, xr.Dataset):\n",
    "                raise ValueError(\n",
    "                    \"Arguments to InferenceData must be xarray Datasets \"\n",
    "                    '(argument \"{}\" was type \"{}\")'.format(key, type(dataset))\n",
    "                )\n",
    "            setattr(self, key, dataset)\n",
    "            self._groups.append(key)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Make string representation of object.\"\"\"\n",
    "        return \"Inference data with groups:\\n\\t> {options}\".format(\n",
    "            options=\"\\n\\t> \".join(self._groups)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def from_netcdf(filename):\n",
    "        \"\"\"Initialize object from a netcdf file.\n",
    "\n",
    "        Expects that the file will have groups, each of which can be loaded by xarray.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            location of netcdf file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        InferenceData object\n",
    "        \"\"\"\n",
    "        groups = {}\n",
    "        with nc.Dataset(filename, mode=\"r\") as data:\n",
    "            data_groups = list(data.groups)\n",
    "\n",
    "        for group in data_groups:\n",
    "            with xr.open_dataset(filename, group=group) as data:\n",
    "                groups[group] = data\n",
    "        return InferenceData(**groups)\n",
    "\n",
    "    def to_netcdf(self, filename, compress=True):\n",
    "        \"\"\"Write InferenceData to file using netcdf4.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            Location to write to\n",
    "        compress : bool\n",
    "            Whether to compress result. Note this saves disk space, but may make\n",
    "            saving and loading somewhat slower (default: True).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Location of netcdf file\n",
    "        \"\"\"\n",
    "        mode = \"w\"  # overwrite first, then append\n",
    "        if self._groups:  # check's whether a group is present or not.\n",
    "            for group in self._groups:\n",
    "                data = getattr(self, group)\n",
    "                kwargs = {}\n",
    "                if compress:\n",
    "                    kwargs[\"encoding\"] = {var_name: {\"zlib\": True} for var_name in data.variables}\n",
    "                data.to_netcdf(filename, mode=mode, group=group, **kwargs)\n",
    "                data.close()\n",
    "                mode = \"a\"\n",
    "        else:  # creates a netcdf file for an empty InferenceData object.\n",
    "            empty_netcdf_file = nc.Dataset(filename, mode=\"w\", format=\"NETCDF4\")\n",
    "            empty_netcdf_file.close()\n",
    "        return filename\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"Concatenate two InferenceData objects.\"\"\"\n",
    "        return concat(self, other, copy=True, inplace=False)\n",
    "\n",
    "    def sel(self, inplace=True, **kwargs):\n",
    "        \"\"\"Perform an xarray selection on all groups.\n",
    "\n",
    "        Loops over all groups to perform Dataset.sel(key=item)\n",
    "        for every kwarg if key is a dimension of the dataset.\n",
    "        The selection is performed inplace.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inplace : bool\n",
    "            If True, modify the InferenceData object inplace, otherwise, return the modified copy.\n",
    "        **kwargs : mapping\n",
    "            It must be accepted by Dataset.sel()\n",
    "        \"\"\"\n",
    "        out = self if inplace else deepcopy(self)\n",
    "        for group in self._groups:\n",
    "            dataset = getattr(self, group)\n",
    "            valid_keys = set(kwargs.keys()).intersection(dataset.dims)\n",
    "            dataset = dataset.sel(**{key: kwargs[key] for key in valid_keys})\n",
    "            setattr(out, group, dataset)\n",
    "        if inplace:\n",
    "            return None\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "@numba.jit(forceobj=True)\n",
    "def concat(*args, dim=None, copy=True, inplace=False, reset_dim=True):\n",
    "    \"\"\"Concatenate InferenceData objects.\n",
    "\n",
    "    Concatenates over `group`, `chain` or `draw`.\n",
    "    By default concatenates over unique groups.\n",
    "    To concatenate over `chain` or `draw` function\n",
    "    needs identical groups and variables.\n",
    "\n",
    "    The `variables` in the `data` -group are merged if `dim` are not found.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    *args : InferenceData\n",
    "        Variable length InferenceData list or\n",
    "        Sequence of InferenceData.\n",
    "    dim : str, optional\n",
    "        If defined, concatenated over the defined dimension.\n",
    "        Dimension which is concatenated. If None, concatenates over\n",
    "        unique groups.\n",
    "    copy : bool\n",
    "        If True, groups are copied to the new InferenceData object.\n",
    "        Used only if `dim` is None.\n",
    "    inplace : bool\n",
    "        If True, merge args to first object.\n",
    "    reset_dim : bool\n",
    "        Valid only if dim is not None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    InferenceData\n",
    "        A new InferenceData object by default.\n",
    "        When `inplace==True` merge args to first arg and return `None`\n",
    "    \"\"\"\n",
    "    # pylint: disable=undefined-loop-variable, too-many-nested-blocks\n",
    "    if len(args) == 0:\n",
    "        if inplace:\n",
    "            return\n",
    "        return InferenceData()\n",
    "\n",
    "    if len(args) == 1 and isinstance(args[0], Sequence):\n",
    "        args = args[0]\n",
    "\n",
    "    # assert that all args are InferenceData\n",
    "    for i, arg in enumerate(args):\n",
    "        if not isinstance(arg, InferenceData):\n",
    "            raise TypeError(\n",
    "                \"Concatenating is supported only\"\n",
    "                \"between InferenceData objects. Input arg {} is {}\".format(i, type(arg))\n",
    "            )\n",
    "\n",
    "    if dim is not None and dim.lower() not in {\"group\", \"chain\", \"draw\"}:\n",
    "        msg = \"Invalid `dim`: {}. Valid `dim` are {}\".format(dim, '{\"group\", \"chain\", \"draw\"}')\n",
    "        raise TypeError(msg)\n",
    "    dim = dim.lower() if dim is not None else dim\n",
    "\n",
    "    if len(args) == 1 and isinstance(args[0], InferenceData):\n",
    "        if inplace:\n",
    "            return None\n",
    "        else:\n",
    "            if copy:\n",
    "                return deepcopy(args[0])\n",
    "            else:\n",
    "                return args[0]\n",
    "\n",
    "    current_time = str(datetime.now())\n",
    "\n",
    "    if not inplace:\n",
    "        # Keep order for python 3.5\n",
    "        inference_data_dict = OrderedDict()\n",
    "\n",
    "    if dim is None:\n",
    "        arg0 = args[0]\n",
    "        arg0_groups = ccopy(arg0._groups)\n",
    "        args_groups = dict()\n",
    "        # check if groups are independent\n",
    "        # Concat over unique groups\n",
    "        for arg in args[1:]:\n",
    "            for group in arg._groups:\n",
    "                if group in args_groups or group in arg0_groups:\n",
    "                    msg = (\n",
    "                        \"Concatenating overlapping groups is not supported unless `dim` is defined.\"\n",
    "                    )\n",
    "                    msg += \" Valid dimensions are `chain` and `draw`.\"\n",
    "                    raise TypeError(msg)\n",
    "            group_data = getattr(arg, group)\n",
    "            args_groups[group] = deepcopy(group_data) if copy else group_data\n",
    "        # add arg0 to args_groups if inplace is False\n",
    "        if not inplace:\n",
    "            for group in arg0_groups:\n",
    "                group_data = getattr(arg0, group)\n",
    "                args_groups[group] = deepcopy(group_data) if copy else group_data\n",
    "\n",
    "        basic_order = [\n",
    "            \"posterior\",\n",
    "            \"posterior_predictive\",\n",
    "            \"sample_stats\",\n",
    "            \"prior\",\n",
    "            \"prior_predictive\",\n",
    "            \"sample_stats_prior\",\n",
    "            \"observed_data\",\n",
    "        ]\n",
    "        other_groups = [group for group in args_groups if group not in basic_order]\n",
    "\n",
    "        for group in basic_order + other_groups:\n",
    "            if group not in args_groups:\n",
    "                continue\n",
    "            if inplace:\n",
    "                arg0._groups.append(group)\n",
    "                setattr(arg0, group, args_groups[group])\n",
    "            else:\n",
    "                inference_data_dict[group] = args_groups[group]\n",
    "        if inplace:\n",
    "            other_groups = [\n",
    "                group for group in arg0_groups if group not in basic_order\n",
    "            ] + other_groups\n",
    "            sorted_groups = [group for group in basic_order + other_groups if group in arg0._groups]\n",
    "            setattr(arg0, \"_groups\", sorted_groups)\n",
    "    else:\n",
    "        arg0 = args[0]\n",
    "        arg0_groups = arg0._groups\n",
    "        for arg in args[1:]:\n",
    "            for group0 in arg0_groups:\n",
    "                if group0 not in arg._groups:\n",
    "                    if group0 == \"observed_data\":\n",
    "                        continue\n",
    "                    msg = \"Mismatch between the groups.\"\n",
    "                    raise TypeError(msg)\n",
    "            for group in arg._groups:\n",
    "                if group != \"observed_data\":\n",
    "                    # assert that groups are equal\n",
    "                    if group not in arg0_groups:\n",
    "                        msg = \"Mismatch between the groups.\"\n",
    "                        raise TypeError(msg)\n",
    "\n",
    "                    # assert that variables are equal\n",
    "                    group_data = getattr(arg, group)\n",
    "                    group_vars = group_data.data_vars\n",
    "\n",
    "                    if not inplace and group in inference_data_dict:\n",
    "                        group0_data = inference_data_dict[group]\n",
    "                    else:\n",
    "                        group0_data = getattr(arg0, group)\n",
    "                    group0_vars = group0_data.data_vars\n",
    "\n",
    "                    for var in group0_vars:\n",
    "                        if var not in group_vars:\n",
    "                            msg = \"Mismatch between the variables.\"\n",
    "                            raise TypeError(msg)\n",
    "\n",
    "                    for var in group_vars:\n",
    "                        if var not in group0_vars:\n",
    "                            msg = \"Mismatch between the variables.\"\n",
    "                            raise TypeError(msg)\n",
    "                        var_dims = getattr(group_data, var).dims\n",
    "                        var0_dims = getattr(group0_data, var).dims\n",
    "                        if var_dims != var0_dims:\n",
    "                            msg = \"Mismatch between the dimensions.\"\n",
    "                            raise TypeError(msg)\n",
    "\n",
    "                        if dim not in var_dims or dim not in var0_dims:\n",
    "                            msg = \"Dimension {} missing.\".format(dim)\n",
    "                            raise TypeError(msg)\n",
    "\n",
    "                    # xr.concat\n",
    "                    concatenated_group = xr.concat((group_data, group0_data), dim=dim)\n",
    "                    if reset_dim:\n",
    "                        concatenated_group[dim] = range(concatenated_group[dim].size)\n",
    "\n",
    "                    # handle attrs\n",
    "                    if hasattr(group0_data, \"attrs\"):\n",
    "                        group0_attrs = deepcopy(getattr(group0_data, \"attrs\"))\n",
    "                    else:\n",
    "                        group0_attrs = OrderedDict()\n",
    "\n",
    "                    if hasattr(group_data, \"attrs\"):\n",
    "                        group_attrs = getattr(group_data, \"attrs\")\n",
    "                    else:\n",
    "                        group_attrs = dict()\n",
    "\n",
    "                    # gather attrs results to group0_attrs\n",
    "                    for attr_key, attr_values in group_attrs.items():\n",
    "                        group0_attr_values = group0_attrs.get(attr_key, None)\n",
    "                        equality = attr_values == group0_attr_values\n",
    "                        if hasattr(equality, \"__iter__\"):\n",
    "                            equality = np.all(equality)\n",
    "                        if equality:\n",
    "                            continue\n",
    "                        # handle special cases:\n",
    "                        if attr_key in (\"created_at\", \"previous_created_at\"):\n",
    "                            # check the defaults\n",
    "                            if not hasattr(group0_attrs, \"previous_created_at\"):\n",
    "                                group0_attrs[\"previous_created_at\"] = []\n",
    "                                if group0_attr_values is not None:\n",
    "                                    group0_attrs[\"previous_created_at\"].append(group0_attr_values)\n",
    "                            # check previous values\n",
    "                            if attr_key == \"previous_created_at\":\n",
    "                                if not isinstance(attr_values, list):\n",
    "                                    attr_values = [attr_values]\n",
    "                                group0_attrs[\"previous_created_at\"].extend(attr_values)\n",
    "                                continue\n",
    "                            # update \"created_at\"\n",
    "                            if group0_attr_values != current_time:\n",
    "                                group0_attrs[attr_key] = current_time\n",
    "                            group0_attrs[\"previous_created_at\"].append(attr_values)\n",
    "\n",
    "                        elif attr_key in group0_attrs:\n",
    "                            combined_key = \"combined_{}\".format(attr_key)\n",
    "                            if combined_key not in group0_attrs:\n",
    "                                group0_attrs[combined_key] = [group0_attr_values]\n",
    "                            group0_attrs[combined_key].append(attr_values)\n",
    "                        else:\n",
    "                            group0_attrs[attr_key] = attr_values\n",
    "                    # update attrs\n",
    "                    setattr(concatenated_group, \"attrs\", group0_attrs)\n",
    "\n",
    "                    if inplace:\n",
    "                        setattr(arg0, group, concatenated_group)\n",
    "                    else:\n",
    "                        inference_data_dict[group] = concatenated_group\n",
    "                else:\n",
    "                    # observed_data\n",
    "                    if group not in arg0_groups:\n",
    "                        setattr(arg0, group, deepcopy(group_data) if copy else group_data)\n",
    "                        arg0._groups.append(group)\n",
    "                        continue\n",
    "\n",
    "                    # assert that variables are equal\n",
    "                    group_data = getattr(arg, group)\n",
    "                    group_vars = group_data.data_vars\n",
    "\n",
    "                    group0_data = getattr(arg0, group)\n",
    "                    if not inplace:\n",
    "                        group0_data = deepcopy(group0_data)\n",
    "                    group0_vars = group0_data.data_vars\n",
    "\n",
    "                    for var in group_vars:\n",
    "                        if var not in group0_vars:\n",
    "                            var_data = getattr(group_data, var)\n",
    "                            arg0.observed_data[var] = var_data\n",
    "                        else:\n",
    "                            var_data = getattr(group_data, var)\n",
    "                            var0_data = getattr(group0_data, var)\n",
    "                            if dim in var_data.dims and dim in var0_data.dims:\n",
    "                                concatenated_var = xr.concat((group_data, group0_data), dim=dim)\n",
    "                                group0_data[var] = concatenated_var\n",
    "\n",
    "                    # handle attrs\n",
    "                    if hasattr(group0_data, \"attrs\"):\n",
    "                        group0_attrs = getattr(group0_data, \"attrs\")\n",
    "                    else:\n",
    "                        group0_attrs = OrderedDict()\n",
    "\n",
    "                    if hasattr(group_data, \"attrs\"):\n",
    "                        group_attrs = getattr(group_data, \"attrs\")\n",
    "                    else:\n",
    "                        group_attrs = dict()\n",
    "\n",
    "                    # gather attrs results to group0_attrs\n",
    "                    for attr_key, attr_values in group_attrs.items():\n",
    "                        group0_attr_values = group0_attrs.get(attr_key, None)\n",
    "                        equality = attr_values == group0_attr_values\n",
    "                        if hasattr(equality, \"__iter__\"):\n",
    "                            equality = np.all(equality)\n",
    "                        if equality:\n",
    "                            continue\n",
    "                        # handle special cases:\n",
    "                        if attr_key in (\"created_at\", \"previous_created_at\"):\n",
    "                            # check the defaults\n",
    "                            if not hasattr(group0_attrs, \"previous_created_at\"):\n",
    "                                group0_attrs[\"previous_created_at\"] = []\n",
    "                                if group0_attr_values is not None:\n",
    "                                    group0_attrs[\"previous_created_at\"].append(group0_attr_values)\n",
    "                            # check previous values\n",
    "                            if attr_key == \"previous_created_at\":\n",
    "                                if not isinstance(attr_values, list):\n",
    "                                    attr_values = [attr_values]\n",
    "                                group0_attrs[\"previous_created_at\"].extend(attr_values)\n",
    "                                continue\n",
    "                            # update \"created_at\"\n",
    "                            if group0_attr_values != current_time:\n",
    "                                group0_attrs[attr_key] = current_time\n",
    "                            group0_attrs[\"previous_created_at\"].append(attr_values)\n",
    "\n",
    "                        elif attr_key in group0_attrs:\n",
    "                            combined_key = \"combined_{}\".format(attr_key)\n",
    "                            if combined_key not in group0_attrs:\n",
    "                                group0_attrs[combined_key] = [group0_attr_values]\n",
    "                            group0_attrs[combined_key].append(attr_values)\n",
    "\n",
    "                        else:\n",
    "                            group0_attrs[attr_key] = attr_values\n",
    "                    # update attrs\n",
    "                    setattr(group0_data, \"attrs\", group0_attrs)\n",
    "\n",
    "                    if inplace:\n",
    "                        setattr(arg0, group, group0_data)\n",
    "                    else:\n",
    "                        inference_data_dict[group] = group0_data\n",
    "\n",
    "    return None if inplace else InferenceData(**inference_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
