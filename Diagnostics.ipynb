{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "from arviz.data import convert_to_dataset\n",
    "from arviz.stats.diagnostics import bfmi,_bfmi,geweke as ge\n",
    "from arviz.stats.diagnostics import ks_summary as ks\n",
    "from arviz.utils import conditional_jit\n",
    "import numpy as np\n",
    "from line_profiler import LineProfiler\n",
    "import numba\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(1000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 ms ± 25.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit bfmi(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.230674 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: bfmi at line 24\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    24                                           def bfmi(data):\n",
      "    25                                               r\"\"\"Calculate the estimated Bayesian fraction of missing information (BFMI).\n",
      "    26                                           \n",
      "    27                                               BFMI quantifies how well momentum resampling matches the marginal energy distribution. For more\n",
      "    28                                               information on BFMI, see https://arxiv.org/pdf/1604.00695v1.pdf. The current advice is that\n",
      "    29                                               values smaller than 0.3 indicate poor sampling. However, this threshold is provisional and may\n",
      "    30                                               change. See http://mc-stan.org/users/documentation/case-studies/pystan_workflow.html for more\n",
      "    31                                               information.\n",
      "    32                                           \n",
      "    33                                               Parameters\n",
      "    34                                               ----------\n",
      "    35                                               data : obj\n",
      "    36                                                   Any object that can be converted to an az.InferenceData object.\n",
      "    37                                                   Refer to documentation of az.convert_to_dataset for details.\n",
      "    38                                                   If InferenceData, energy variable needs to be found.\n",
      "    39                                           \n",
      "    40                                               Returns\n",
      "    41                                               -------\n",
      "    42                                               z : array\n",
      "    43                                                   The Bayesian fraction of missing information of the model and trace. One element per\n",
      "    44                                                   chain in the trace.\n",
      "    45                                               \"\"\"\n",
      "    46         1          3.0      3.0      0.0      if isinstance(data, np.ndarray):\n",
      "    47         1     230671.0 230671.0    100.0          return _bfmi(data)\n",
      "    48                                           \n",
      "    49                                               dataset = convert_to_dataset(data, group=\"sample_stats\")\n",
      "    50                                               if not hasattr(dataset, \"energy\"):\n",
      "    51                                                   raise TypeError(\"Energy variable was not found.\")\n",
      "    52                                               return _bfmi(dataset.energy)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(bfmi)\n",
    "wrapper(data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.205684 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: _bfmi at line 475\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   475                                           def _bfmi(energy):\n",
      "   476                                               r\"\"\"Calculate the estimated Bayesian fraction of missing information (BFMI).\n",
      "   477                                           \n",
      "   478                                               BFMI quantifies how well momentum resampling matches the marginal energy distribution. For more\n",
      "   479                                               information on BFMI, see https://arxiv.org/pdf/1604.00695v1.pdf. The current advice is that\n",
      "   480                                               values smaller than 0.3 indicate poor sampling. However, this threshold is provisional and may\n",
      "   481                                               change. See http://mc-stan.org/users/documentation/case-studies/pystan_workflow.html for more\n",
      "   482                                               information.\n",
      "   483                                           \n",
      "   484                                               Parameters\n",
      "   485                                               ----------\n",
      "   486                                               energy : NumPy array\n",
      "   487                                                   Should be extracted from a gradient based sampler, such as in Stan or PyMC3. Typically,\n",
      "   488                                                   after converting a trace or fit to InferenceData, the energy will be in\n",
      "   489                                                   `data.sample_stats.energy`.\n",
      "   490                                           \n",
      "   491                                               Returns\n",
      "   492                                               -------\n",
      "   493                                               z : array\n",
      "   494                                                   The Bayesian fraction of missing information of the model and trace. One element per\n",
      "   495                                                   chain in the trace.\n",
      "   496                                               \"\"\"\n",
      "   497         1         16.0     16.0      0.0      energy_mat = np.atleast_2d(energy)\n",
      "   498         1     108839.0 108839.0     52.9      num = np.square(np.diff(energy_mat, axis=1)).mean(axis=1)  # pylint: disable=no-member\n",
      "   499         1      96804.0  96804.0     47.1      den = np.var(energy_mat, axis=1)\n",
      "   500         1         25.0     25.0      0.0      return num / den\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(_bfmi)\n",
    "wrapper(data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def _var_1d(data):\n",
    "    a,b = 0,0\n",
    "    for i in data:\n",
    "        a = a+i\n",
    "        b = b+i*i\n",
    "    return b/len(data)-((a/len(data))**2)\n",
    "\n",
    "@numba.njit\n",
    "def _var_2d(data):\n",
    "    a,b = data.shape\n",
    "    var = np.zeros(a)\n",
    "    for i in range(0,a):\n",
    "        var[i] = _var_1d(data[i,:])\n",
    "    return var\n",
    "\n",
    "\n",
    "def _bfmi_jit(energy):\n",
    "    energy_mat = np.atleast_2d(energy)\n",
    "    if energy_mat.ndim==2:\n",
    "        num = np.square(np.diff(energy_mat, axis=1)).mean(axis=1)  # pylint: disable=no-member\n",
    "        den = _var_2d(energy_mat)\n",
    "    return num / den\n",
    "\n",
    "def bfmi_new(data):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return _bfmi_jit(data)\n",
    "\n",
    "    dataset = convert_to_dataset(data, group=\"sample_stats\")\n",
    "    if not hasattr(dataset, \"energy\"):\n",
    "        raise TypeError(\"Energy variable was not found.\")\n",
    "    return _bfmi_jit(dataset.energy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 ms ± 7.26 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit bfmi_new(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 ms ± 22.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.diagnostics.bfmi(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.9 ms ± 3.17 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit bfmi_new(np.random.randn(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.6 ms ± 4.28 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.bfmi(np.random.randn(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 ms ± 2.02 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit bfmi_new(az.load_arviz_data(\"centered_eight\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 ms ± 7.72 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.bfmi(az.load_arviz_data(\"centered_eight\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Much better improvement on larger datasets. A gain on a few milliseconds on school'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Much better improvement on larger datasets. A gain on a few milliseconds on school'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ks_summary'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"ks_summary\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(10_00_00,1000)\n",
    "school  = az.load_arviz_data(\"centered_eight\").posterior[\"mu\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ks_summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 13.4547 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: ks_summary at line 448\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   448                                           def ks_summary(pareto_tail_indices):\n",
      "   449                                               \"\"\"Display a summary of Pareto tail indices.\n",
      "   450                                           \n",
      "   451                                               Parameters\n",
      "   452                                               ----------\n",
      "   453                                               pareto_tail_indices : array\n",
      "   454                                                 Pareto tail indices.\n",
      "   455                                           \n",
      "   456                                               Returns\n",
      "   457                                               -------\n",
      "   458                                               df_k : dataframe\n",
      "   459                                                 Dataframe containing k diagnostic values.\n",
      "   460                                               \"\"\"\n",
      "   461         1   12123053.0 12123053.0     90.1      kcounts, _ = np.histogram(pareto_tail_indices, bins=[-np.Inf, 0.5, 0.7, 1, np.Inf])\n",
      "   462         1         23.0     23.0      0.0      kprop = kcounts / len(pareto_tail_indices) * 100\n",
      "   463         1         13.0     13.0      0.0      df_k = pd.DataFrame(\n",
      "   464         1     822678.0 822678.0      6.1          dict(_=[\"(good)\", \"(ok)\", \"(bad)\", \"(very bad)\"], Count=kcounts, Pct=kprop)\n",
      "   465         1       1300.0   1300.0      0.0      ).rename(index={0: \"(-Inf, 0.5]\", 1: \" (0.5, 0.7]\", 2: \"   (0.7, 1]\", 3: \"   (1, Inf)\"})\n",
      "   466                                           \n",
      "   467         1     507609.0 507609.0      3.8      if np.sum(kcounts[1:]) == 0:\n",
      "   468                                                   warnings.warn(\"All Pareto k estimates are good (k < 0.5)\")\n",
      "   469         1         46.0     46.0      0.0      elif np.sum(kcounts[2:]) == 0:\n",
      "   470                                                   warnings.warn(\"All Pareto k estimates are ok (k < 0.7)\")\n",
      "   471                                           \n",
      "   472         1          2.0      2.0      0.0      return df_k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(ks)\n",
    "wrapper(data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bottleneck ar np.historgram'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''bottleneck ar np.historgram'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@conditional_jit\n",
    "def _histogram(data):\n",
    "    kcounts, _ = np.histogram(data,bins=[-np.Inf, 0.5, 0.7, 1, np.Inf])\n",
    "    return kcounts\n",
    "\n",
    "\n",
    "def ks_summary_new(pareto_tail_indices):\n",
    "    kcounts = _histogram(pareto_tail_indices)\n",
    "    kprop = kcounts / len(pareto_tail_indices) * 100\n",
    "    df_k = pd.DataFrame(\n",
    "        dict(_=[\"(good)\", \"(ok)\", \"(bad)\", \"(very bad)\"], Count=kcounts, Pct=kprop)\n",
    "    ).rename(index={0: \"(-Inf, 0.5]\", 1: \" (0.5, 0.7]\", 2: \"   (0.7, 1]\", 3: \"   (1, Inf)\"})\n",
    "\n",
    "    if np.sum(kcounts[1:]) == 0:\n",
    "        warnings.warn(\"All Pareto k estimates are good (k < 0.5)\")\n",
    "    elif np.sum(kcounts[2:]) == 0:\n",
    "        warnings.warn(\"All Pareto k estimates are ok (k < 0.7)\")\n",
    "\n",
    "    return df_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>Count</th>\n",
       "      <th>Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-Inf, 0.5]</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.5, 0.7]</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.7, 1]</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, Inf)</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                _  Count   Pct\n",
       "(-Inf, 0.5]  True   True  True\n",
       " (0.5, 0.7]  True   True  True\n",
       "   (0.7, 1]  True   True  True\n",
       "   (1, Inf)  True   True  True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_summary_new(data)==ks(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.38 s ± 17.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks_summary_new(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.5 s ± 173 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.39 ms ± 28.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks_summary_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.77 ms ± 75.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777 ms ± 10.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks_summary_new(np.random.randn(10000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.74 s ± 11.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks(np.random.randn(10000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PHEW. 10 times faster on large datasets. Much better performance on every dataset'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''PHEW. 10 times faster on large datasets. Much better performance on every dataset'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"geweke'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"geweke\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(10000000)\n",
    "school = az.load_arviz_data(\"centered_eight\").posterior[\"mu\"].values\n",
    "school = school[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 8.04882 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: geweke at line 376\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   376                                           def geweke(ary, first=0.1, last=0.5, intervals=20):\n",
      "   377                                               r\"\"\"Compute z-scores for convergence diagnostics.\n",
      "   378                                           \n",
      "   379                                               Compare the mean of the first % of series with the mean of the last % of series. x is divided\n",
      "   380                                               into a number of segments for which this difference is computed. If the series is converged,\n",
      "   381                                               this score should oscillate between -1 and 1.\n",
      "   382                                           \n",
      "   383                                               Parameters\n",
      "   384                                               ----------\n",
      "   385                                               ary : 1D array-like\n",
      "   386                                                 The trace of some stochastic parameter.\n",
      "   387                                               first : float\n",
      "   388                                                 The fraction of series at the beginning of the trace.\n",
      "   389                                               last : float\n",
      "   390                                                 The fraction of series at the end to be compared with the section\n",
      "   391                                                 at the beginning.\n",
      "   392                                               intervals : int\n",
      "   393                                                 The number of segments.\n",
      "   394                                           \n",
      "   395                                               Returns\n",
      "   396                                               -------\n",
      "   397                                               scores : list [[]]\n",
      "   398                                                 Return a list of [i, score], where i is the starting index for each interval and score the\n",
      "   399                                                 Geweke score on the interval.\n",
      "   400                                           \n",
      "   401                                               Notes\n",
      "   402                                               -----\n",
      "   403                                               The Geweke score on some series x is computed by:\n",
      "   404                                           \n",
      "   405                                                 .. math:: \\frac{E[x_s] - E[x_e]}{\\sqrt{V[x_s] + V[x_e]}}\n",
      "   406                                           \n",
      "   407                                               where :math:`E` stands for the mean, :math:`V` the variance,\n",
      "   408                                               :math:`x_s` a section at the start of the series and\n",
      "   409                                               :math:`x_e` a section at the end of the series.\n",
      "   410                                           \n",
      "   411                                               References\n",
      "   412                                               ----------\n",
      "   413                                               Geweke (1992)\n",
      "   414                                               \"\"\"\n",
      "   415                                               # Filter out invalid intervals\n",
      "   416         3         11.0      3.7      0.0      for interval in (first, last):\n",
      "   417         2          7.0      3.5      0.0          if interval <= 0 or interval >= 1:\n",
      "   418                                                       raise ValueError(\"Invalid intervals for Geweke convergence analysis\", (first, last))\n",
      "   419         1          3.0      3.0      0.0      if first + last >= 1:\n",
      "   420                                                   raise ValueError(\"Invalid intervals for Geweke convergence analysis\", (first, last))\n",
      "   421                                           \n",
      "   422                                               # Initialize list of z-scores\n",
      "   423         1          3.0      3.0      0.0      zscores = []\n",
      "   424                                           \n",
      "   425                                               # Last index value\n",
      "   426         1          5.0      5.0      0.0      end = len(ary) - 1\n",
      "   427                                           \n",
      "   428                                               # Start intervals going up to the <last>% of the chain\n",
      "   429         1          4.0      4.0      0.0      last_start_idx = (1 - last) * end\n",
      "   430                                           \n",
      "   431                                               # Calculate starting indices\n",
      "   432         1      42353.0  42353.0      0.5      start_indices = np.linspace(0, last_start_idx, num=intervals, endpoint=True, dtype=int)\n",
      "   433                                           \n",
      "   434                                               # Loop over start indices\n",
      "   435       201        608.0      3.0      0.0      for start in start_indices:\n",
      "   436                                                   # Calculate slices\n",
      "   437       200       6700.0     33.5      0.1          first_slice = ary[start : start + int(first * (end - start))]\n",
      "   438       200       2871.0     14.4      0.0          last_slice = ary[int(end - last * (end - start)) :]\n",
      "   439                                           \n",
      "   440       200     827890.0   4139.4     10.3          z_score = first_slice.mean() - last_slice.mean()\n",
      "   441       200    7167027.0  35835.1     89.0          z_score /= np.sqrt(first_slice.var() + last_slice.var())\n",
      "   442                                           \n",
      "   443       200       1186.0      5.9      0.0          zscores.append([start, z_score])\n",
      "   444                                           \n",
      "   445         1        157.0    157.0      0.0      return np.array(zscores)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(ge)\n",
    "wrapper(data,0.1,0.5,200)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@conditional_jit\n",
    "def _var_1d(data):\n",
    "    a,b = 0,0\n",
    "    for i in data:\n",
    "        a = a+i\n",
    "        b = b+i*i\n",
    "    return b/len(data)-((a/len(data))**2)\n",
    "\n",
    "\n",
    "@numba.vectorize(nopython=True)   ##Remember to make a conditional_vectorize function\n",
    "def _sqr(a,b):\n",
    "    return np.sqrt(a+b)\n",
    "\n",
    "\n",
    "@conditional_jit\n",
    "def geweke_new(ary, first=0.1, last=0.5, intervals=20):\n",
    "    # Filter out invalid intervals\n",
    "    for interval in (first, last):\n",
    "        if interval <= 0 or interval >= 1:\n",
    "            raise ValueError(\"Invalid intervals for Geweke convergence analysis\", (first, last))\n",
    "    if first + last >= 1:\n",
    "        raise ValueError(\"Invalid intervals for Geweke convergence analysis\", (first, last))\n",
    "\n",
    "    # Initialize list of z-scores\n",
    "    zscores = []\n",
    "\n",
    "    # Last index value\n",
    "    end = len(ary) - 1\n",
    "\n",
    "    # Start intervals going up to the <last>% of the chain\n",
    "    last_start_idx = (1 - last) * end\n",
    "\n",
    "    # Calculate starting indices\n",
    "    start_indices = np.linspace(0, last_start_idx, num=intervals, endpoint=True, dtype=int)\n",
    "\n",
    "    # Loop over start indices\n",
    "    for start in start_indices:\n",
    "        # Calculate slices\n",
    "        first_slice = ary[start : start + int(first * (end - start))]\n",
    "        last_slice = ary[int(end - last * (end - start)) :]\n",
    "\n",
    "        z_score = first_slice.mean() - last_slice.mean()\n",
    "        D = _sqr(_var_1d(first_slice), _var_1d(last_slice))\n",
    "        z_score = z_score/D\n",
    "\n",
    "        zscores.append([start, z_score])\n",
    "\n",
    "    return np.array(zscores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 ms ± 4.49 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit geweke_new(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657 ms ± 19.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.geweke(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.77 s ± 139 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit geweke_new(data,intervals=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 s ± 202 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.geweke(data,intervals=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(geweke_new(data,intervals=500), az.geweke(data,intervals=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 ms ± 116 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit geweke_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.28 ms ± 68.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.geweke(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
