{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "from arviz.data import convert_to_dataset\n",
    "from arviz.stats.diagnostics import bfmi,_bfmi,geweke as ge,rhat as rh,_ess as es\n",
    "from arviz.stats.diagnostics import _rhat,_split_chains,_z_scale\n",
    "from arviz.stats.diagnostics import _rhat_rank as rk\n",
    "from arviz.stats.diagnostics import ks_summary as ks\n",
    "from arviz.stats.diagnostics import _mc_error as me, _mcse_mean, _mcse_quantile, _mcse_sd as msd,_ess_mean,_ess_sd\n",
    "from arviz.utils import conditional_jit\n",
    "from arviz.stats.stats_utils import not_valid as _not_valid, autocov as _autocov\n",
    "import numpy as np\n",
    "from line_profiler import LineProfiler\n",
    "import numba\n",
    "import pandas as pd\n",
    "from scipy.fftpack import next_fast_len\n",
    "from scipy.stats.mstats import mquantiles\n",
    "from scipy import stats\n",
    "from xarray import apply_ufunc\n",
    "import xarray as xr\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(1000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 ms ± 3.85 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit bfmi(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.208983 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: bfmi at line 24\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    24                                           def bfmi(data):\n",
      "    25                                               r\"\"\"Calculate the estimated Bayesian fraction of missing information (BFMI).\n",
      "    26                                           \n",
      "    27                                               BFMI quantifies how well momentum resampling matches the marginal energy distribution. For more\n",
      "    28                                               information on BFMI, see https://arxiv.org/pdf/1604.00695v1.pdf. The current advice is that\n",
      "    29                                               values smaller than 0.3 indicate poor sampling. However, this threshold is provisional and may\n",
      "    30                                               change. See http://mc-stan.org/users/documentation/case-studies/pystan_workflow.html for more\n",
      "    31                                               information.\n",
      "    32                                           \n",
      "    33                                               Parameters\n",
      "    34                                               ----------\n",
      "    35                                               data : obj\n",
      "    36                                                   Any object that can be converted to an az.InferenceData object.\n",
      "    37                                                   Refer to documentation of az.convert_to_dataset for details.\n",
      "    38                                                   If InferenceData, energy variable needs to be found.\n",
      "    39                                           \n",
      "    40                                               Returns\n",
      "    41                                               -------\n",
      "    42                                               z : array\n",
      "    43                                                   The Bayesian fraction of missing information of the model and trace. One element per\n",
      "    44                                                   chain in the trace.\n",
      "    45                                           \n",
      "    46                                               Examples\n",
      "    47                                               --------\n",
      "    48                                               Compute the BFMI of an InferenceData object\n",
      "    49                                           \n",
      "    50                                               .. ipython::\n",
      "    51                                           \n",
      "    52                                                   In [1]: import arviz as az\n",
      "    53                                                      ...: data = az.load_arviz_data('radon')\n",
      "    54                                                      ...: az.bfmi(data)\n",
      "    55                                           \n",
      "    56                                               \"\"\"\n",
      "    57         1          3.0      3.0      0.0      if isinstance(data, np.ndarray):\n",
      "    58         1     208980.0 208980.0    100.0          return _bfmi(data)\n",
      "    59                                           \n",
      "    60                                               dataset = convert_to_dataset(data, group=\"sample_stats\")\n",
      "    61                                               if not hasattr(dataset, \"energy\"):\n",
      "    62                                                   raise TypeError(\"Energy variable was not found.\")\n",
      "    63                                               return _bfmi(dataset.energy)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(bfmi)\n",
    "wrapper(data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.203059 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: _bfmi at line 547\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   547                                           def _bfmi(energy):\n",
      "   548                                               r\"\"\"Calculate the estimated Bayesian fraction of missing information (BFMI).\n",
      "   549                                           \n",
      "   550                                               BFMI quantifies how well momentum resampling matches the marginal energy distribution. For more\n",
      "   551                                               information on BFMI, see https://arxiv.org/pdf/1604.00695v1.pdf. The current advice is that\n",
      "   552                                               values smaller than 0.3 indicate poor sampling. However, this threshold is provisional and may\n",
      "   553                                               change. See http://mc-stan.org/users/documentation/case-studies/pystan_workflow.html for more\n",
      "   554                                               information.\n",
      "   555                                           \n",
      "   556                                               Parameters\n",
      "   557                                               ----------\n",
      "   558                                               energy : NumPy array\n",
      "   559                                                   Should be extracted from a gradient based sampler, such as in Stan or PyMC3. Typically,\n",
      "   560                                                   after converting a trace or fit to InferenceData, the energy will be in\n",
      "   561                                                   `data.sample_stats.energy`.\n",
      "   562                                           \n",
      "   563                                               Returns\n",
      "   564                                               -------\n",
      "   565                                               z : array\n",
      "   566                                                   The Bayesian fraction of missing information of the model and trace. One element per\n",
      "   567                                                   chain in the trace.\n",
      "   568                                               \"\"\"\n",
      "   569         1         17.0     17.0      0.0      energy_mat = np.atleast_2d(energy)\n",
      "   570         1     109507.0 109507.0     53.9      num = np.square(np.diff(energy_mat, axis=1)).mean(axis=1)  # pylint: disable=no-member\n",
      "   571         1      93512.0  93512.0     46.1      den = np.var(energy_mat, axis=1)\n",
      "   572         1         23.0     23.0      0.0      return num / den\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(_bfmi)\n",
    "wrapper(data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def _var_1d(data):\n",
    "    a,b = 0,0\n",
    "    for i in data:\n",
    "        a = a+i\n",
    "        b = b+i*i\n",
    "    return b/len(data)-((a/len(data))**2)\n",
    "\n",
    "@numba.njit\n",
    "def _var_2d(data):\n",
    "    a,b = data.shape\n",
    "    var = np.zeros(a)\n",
    "    for i in range(0,a):\n",
    "        var[i] = _var_1d(data[i,:])\n",
    "    return var\n",
    "\n",
    "\n",
    "def _bfmi_jit(energy):\n",
    "    energy_mat = np.atleast_2d(energy)\n",
    "    if energy_mat.ndim==2:\n",
    "        num = np.square(np.diff(energy_mat, axis=1)).mean(axis=1)  # pylint: disable=no-member\n",
    "        den = _var_2d(energy_mat)\n",
    "    return num / den\n",
    "\n",
    "def bfmi_new(data):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return _bfmi_jit(data)\n",
    "\n",
    "    dataset = convert_to_dataset(data, group=\"sample_stats\")\n",
    "    if not hasattr(dataset, \"energy\"):\n",
    "        raise TypeError(\"Energy variable was not found.\")\n",
    "    return _bfmi_jit(dataset.energy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 ms ± 3.39 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit bfmi_new(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 ms ± 6.15 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.stats.diagnostics.bfmi(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.4 ms ± 6.96 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit bfmi_new(np.random.randn(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.8 ms ± 6.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.bfmi(np.random.randn(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.1 ms ± 991 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit bfmi_new(az.load_arviz_data(\"centered_eight\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 ms ± 6.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.bfmi(az.load_arviz_data(\"centered_eight\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Much better improvement on larger datasets. A gain on a few milliseconds on school'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Much better improvement on larger datasets. A gain on a few milliseconds on school'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ks_summary'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"ks_summary\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(10_00_00,1000)\n",
    "school  = az.load_arviz_data(\"centered_eight\").posterior[\"mu\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ks_summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 11.7259 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: ks_summary at line 520\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   520                                           def ks_summary(pareto_tail_indices):\n",
      "   521                                               \"\"\"Display a summary of Pareto tail indices.\n",
      "   522                                           \n",
      "   523                                               Parameters\n",
      "   524                                               ----------\n",
      "   525                                               pareto_tail_indices : array\n",
      "   526                                                 Pareto tail indices.\n",
      "   527                                           \n",
      "   528                                               Returns\n",
      "   529                                               -------\n",
      "   530                                               df_k : dataframe\n",
      "   531                                                 Dataframe containing k diagnostic values.\n",
      "   532                                               \"\"\"\n",
      "   533         1   11692814.0 11692814.0     99.7      kcounts, _ = np.histogram(pareto_tail_indices, bins=[-np.Inf, 0.5, 0.7, 1, np.Inf])\n",
      "   534         1         30.0     30.0      0.0      kprop = kcounts / len(pareto_tail_indices) * 100\n",
      "   535         1         23.0     23.0      0.0      df_k = pd.DataFrame(\n",
      "   536         1      31473.0  31473.0      0.3          dict(_=[\"(good)\", \"(ok)\", \"(bad)\", \"(very bad)\"], Count=kcounts, Pct=kprop)\n",
      "   537         1       1455.0   1455.0      0.0      ).rename(index={0: \"(-Inf, 0.5]\", 1: \" (0.5, 0.7]\", 2: \"   (0.7, 1]\", 3: \"   (1, Inf)\"})\n",
      "   538                                           \n",
      "   539         1         39.0     39.0      0.0      if np.sum(kcounts[1:]) == 0:\n",
      "   540                                                   warnings.warn(\"All Pareto k estimates are good (k < 0.5)\")\n",
      "   541         1         16.0     16.0      0.0      elif np.sum(kcounts[2:]) == 0:\n",
      "   542                                                   warnings.warn(\"All Pareto k estimates are ok (k < 0.7)\")\n",
      "   543                                           \n",
      "   544         1          1.0      1.0      0.0      return df_k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(ks)\n",
    "wrapper(data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bottleneck ar np.historgram'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''bottleneck ar np.historgram'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@conditional_jit\n",
    "def _histogram(data):\n",
    "    kcounts, _ = np.histogram(data,bins=[-np.Inf, 0.5, 0.7, 1, np.Inf])\n",
    "    return kcounts\n",
    "\n",
    "\n",
    "def ks_summary_new(pareto_tail_indices):\n",
    "    kcounts = _histogram(pareto_tail_indices)\n",
    "    kprop = kcounts / len(pareto_tail_indices) * 100\n",
    "    df_k = pd.DataFrame(\n",
    "        dict(_=[\"(good)\", \"(ok)\", \"(bad)\", \"(very bad)\"], Count=kcounts, Pct=kprop)\n",
    "    ).rename(index={0: \"(-Inf, 0.5]\", 1: \" (0.5, 0.7]\", 2: \"   (0.7, 1]\", 3: \"   (1, Inf)\"})\n",
    "\n",
    "    if np.sum(kcounts[1:]) == 0:\n",
    "        warnings.warn(\"All Pareto k estimates are good (k < 0.5)\")\n",
    "    elif np.sum(kcounts[2:]) == 0:\n",
    "        warnings.warn(\"All Pareto k estimates are ok (k < 0.7)\")\n",
    "\n",
    "    return df_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>Count</th>\n",
       "      <th>Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-Inf, 0.5]</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.5, 0.7]</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.7, 1]</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, Inf)</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                _  Count   Pct\n",
       "(-Inf, 0.5]  True   True  True\n",
       " (0.5, 0.7]  True   True  True\n",
       "   (0.7, 1]  True   True  True\n",
       "   (1, Inf)  True   True  True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_summary_new(data)==ks(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.37 s ± 4.98 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks_summary_new(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2 s ± 14.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.46 ms ± 115 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks_summary_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95 ms ± 142 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832 ms ± 23.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks_summary_new(np.random.randn(10000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.84 s ± 46.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ks(np.random.randn(10000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PHEW. 10 times faster on large datasets. Much better performance on every dataset'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''PHEW. 10 times faster on large datasets. Much better performance on every dataset'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"geweke'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"geweke\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(10000000)\n",
    "school = az.load_arviz_data(\"centered_eight\").posterior[\"mu\"].values\n",
    "school = school[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 8.12892 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: geweke at line 448\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   448                                           def geweke(ary, first=0.1, last=0.5, intervals=20):\n",
      "   449                                               r\"\"\"Compute z-scores for convergence diagnostics.\n",
      "   450                                           \n",
      "   451                                               Compare the mean of the first % of series with the mean of the last % of series. x is divided\n",
      "   452                                               into a number of segments for which this difference is computed. If the series is converged,\n",
      "   453                                               this score should oscillate between -1 and 1.\n",
      "   454                                           \n",
      "   455                                               Parameters\n",
      "   456                                               ----------\n",
      "   457                                               ary : 1D array-like\n",
      "   458                                                 The trace of some stochastic parameter.\n",
      "   459                                               first : float\n",
      "   460                                                 The fraction of series at the beginning of the trace.\n",
      "   461                                               last : float\n",
      "   462                                                 The fraction of series at the end to be compared with the section\n",
      "   463                                                 at the beginning.\n",
      "   464                                               intervals : int\n",
      "   465                                                 The number of segments.\n",
      "   466                                           \n",
      "   467                                               Returns\n",
      "   468                                               -------\n",
      "   469                                               scores : list [[]]\n",
      "   470                                                 Return a list of [i, score], where i is the starting index for each interval and score the\n",
      "   471                                                 Geweke score on the interval.\n",
      "   472                                           \n",
      "   473                                               Notes\n",
      "   474                                               -----\n",
      "   475                                               The Geweke score on some series x is computed by:\n",
      "   476                                           \n",
      "   477                                                 .. math:: \\frac{E[x_s] - E[x_e]}{\\sqrt{V[x_s] + V[x_e]}}\n",
      "   478                                           \n",
      "   479                                               where :math:`E` stands for the mean, :math:`V` the variance,\n",
      "   480                                               :math:`x_s` a section at the start of the series and\n",
      "   481                                               :math:`x_e` a section at the end of the series.\n",
      "   482                                           \n",
      "   483                                               References\n",
      "   484                                               ----------\n",
      "   485                                               * Geweke (1992)\n",
      "   486                                               \"\"\"\n",
      "   487                                               # Filter out invalid intervals\n",
      "   488         3         35.0     11.7      0.0      for interval in (first, last):\n",
      "   489         2          7.0      3.5      0.0          if interval <= 0 or interval >= 1:\n",
      "   490                                                       raise ValueError(\"Invalid intervals for Geweke convergence analysis\", (first, last))\n",
      "   491         1          2.0      2.0      0.0      if first + last >= 1:\n",
      "   492                                                   raise ValueError(\"Invalid intervals for Geweke convergence analysis\", (first, last))\n",
      "   493                                           \n",
      "   494                                               # Initialize list of z-scores\n",
      "   495         1          1.0      1.0      0.0      zscores = []\n",
      "   496                                           \n",
      "   497                                               # Last index value\n",
      "   498         1          4.0      4.0      0.0      end = len(ary) - 1\n",
      "   499                                           \n",
      "   500                                               # Start intervals going up to the <last>% of the chain\n",
      "   501         1          3.0      3.0      0.0      last_start_idx = (1 - last) * end\n",
      "   502                                           \n",
      "   503                                               # Calculate starting indices\n",
      "   504         1        308.0    308.0      0.0      start_indices = np.linspace(0, last_start_idx, num=intervals, endpoint=True, dtype=int)\n",
      "   505                                           \n",
      "   506                                               # Loop over start indices\n",
      "   507       201        736.0      3.7      0.0      for start in start_indices:\n",
      "   508                                                   # Calculate slices\n",
      "   509       200       6890.0     34.5      0.1          first_slice = ary[start : start + int(first * (end - start))]\n",
      "   510       200       3005.0     15.0      0.0          last_slice = ary[int(end - last * (end - start)) :]\n",
      "   511                                           \n",
      "   512       200     897535.0   4487.7     11.0          z_score = first_slice.mean() - last_slice.mean()\n",
      "   513       200    7218964.0  36094.8     88.8          z_score /= np.sqrt(first_slice.var() + last_slice.var())\n",
      "   514                                           \n",
      "   515       200       1257.0      6.3      0.0          zscores.append([start, z_score])\n",
      "   516                                           \n",
      "   517         1        175.0    175.0      0.0      return np.array(zscores)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(ge)\n",
    "wrapper(data,0.1,0.5,200)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@conditional_jit\n",
    "def _var_1d(data):\n",
    "    a,b = 0,0\n",
    "    for i in data:\n",
    "        a = a+i\n",
    "        b = b+i*i\n",
    "    return b/len(data)-((a/len(data))**2)\n",
    "\n",
    "\n",
    "@numba.vectorize(nopython=True)   ##Remember to make a conditional_vectorize function\n",
    "def _sqr(a,b):\n",
    "    return np.sqrt(a+b)\n",
    "\n",
    "\n",
    "@conditional_jit\n",
    "def geweke_new(ary, first=0.1, last=0.5, intervals=20):\n",
    "    # Filter out invalid intervals\n",
    "    for interval in (first, last):\n",
    "        if interval <= 0 or interval >= 1:\n",
    "            raise ValueError(\"Invalid intervals for Geweke convergence analysis\", (first, last))\n",
    "    if first + last >= 1:\n",
    "        raise ValueError(\"Invalid intervals for Geweke convergence analysis\", (first, last))\n",
    "\n",
    "    # Initialize list of z-scores\n",
    "    zscores = []\n",
    "\n",
    "    # Last index value\n",
    "    end = len(ary) - 1\n",
    "\n",
    "    # Start intervals going up to the <last>% of the chain\n",
    "    last_start_idx = (1 - last) * end\n",
    "\n",
    "    # Calculate starting indices\n",
    "    start_indices = np.linspace(0, last_start_idx, num=intervals, endpoint=True, dtype=int)\n",
    "\n",
    "    # Loop over start indices\n",
    "    for start in start_indices:\n",
    "        # Calculate slices\n",
    "        first_slice = ary[start : start + int(first * (end - start))]\n",
    "        last_slice = ary[int(end - last * (end - start)) :]\n",
    "\n",
    "        z_score = first_slice.mean() - last_slice.mean()\n",
    "        D = _sqr(_var_1d(first_slice), _var_1d(last_slice))\n",
    "        z_score = z_score/D\n",
    "\n",
    "        zscores.append([start, z_score])\n",
    "\n",
    "    return np.array(zscores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236 ms ± 3.43 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit geweke_new(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737 ms ± 11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.geweke(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.82 s ± 195 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit geweke_new(data,intervals=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4 s ± 395 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.geweke(data,intervals=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(geweke_new(data,intervals=500), az.geweke(data,intervals=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.54 ms ± 150 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit geweke_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.75 ms ± 157 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.geweke(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"GWEKE WORKS WELL'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"GWEKE WORKS WELL\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ess'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"ess\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = np.random.randn(1000,1000)\n",
    "dict_data = {\"posterior\":numpy_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555 ms ± 9.24 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.ess(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567 ms ± 24.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit az.ess(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.572761 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: ess at line 132\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   132                                           def ess(data, *, var_names=None, method=\"bulk\", relative=False, prob=None):\n",
      "   133                                               r\"\"\"Calculate estimate of the effective sample size.\n",
      "   134                                           \n",
      "   135                                               Parameters\n",
      "   136                                               ----------\n",
      "   137                                               data : obj\n",
      "   138                                                   Any object that can be converted to an az.InferenceData object.\n",
      "   139                                                   Refer to documentation of az.convert_to_dataset for details.\n",
      "   140                                                   For ndarray: shape = (chain, draw).\n",
      "   141                                                   For n-dimensional ndarray transform first to dataset with az.convert_to_dataset.\n",
      "   142                                               var_names : list\n",
      "   143                                                   Names of variables to include in the effective_sample_size_mean report\n",
      "   144                                               method : str\n",
      "   145                                                   Select ess method. Valid methods are:\n",
      "   146                                           \n",
      "   147                                                   - \"bulk\"\n",
      "   148                                                   - \"tail\"     # prob, optional\n",
      "   149                                                   - \"quantile\" # prob\n",
      "   150                                                   - \"mean\" (old ess)\n",
      "   151                                                   - \"sd\"\n",
      "   152                                                   - \"median\"\n",
      "   153                                                   - \"mad\" (mean absolute deviance)\n",
      "   154                                                   - \"z_scale\"\n",
      "   155                                                   - \"folded\"\n",
      "   156                                                   - \"identity\"\n",
      "   157                                           \n",
      "   158                                               relative : bool\n",
      "   159                                                   Return relative ess\n",
      "   160                                                   `ress = ess / n`\n",
      "   161                                               prob : float, optional\n",
      "   162                                                   probability value for \"tail\" and \"quantile\" ess functions.\n",
      "   163                                           \n",
      "   164                                               Returns\n",
      "   165                                               -------\n",
      "   166                                               xarray.Dataset\n",
      "   167                                                   Return the effective sample size, :math:`\\hat{N}_{eff}`\n",
      "   168                                           \n",
      "   169                                               Notes\n",
      "   170                                               -----\n",
      "   171                                               The basic ess diagnostic is computed by:\n",
      "   172                                           \n",
      "   173                                               .. math:: \\hat{N}_{eff} = \\frac{MN}{\\hat{\\tau}}\n",
      "   174                                               .. math:: \\hat{\\tau} = -1 + 2 \\sum_{t'=0}^K \\hat{P}_{t'}\n",
      "   175                                           \n",
      "   176                                               where :math:`M` is the number of chains, :math:`N` the number of draws,\n",
      "   177                                               :math:`\\hat{\\rho}_t` is the estimated _autocorrelation at lag :math:`t`, and\n",
      "   178                                               :math:`K` is the last integer for which :math:`\\hat{P}_{K} = \\hat{\\rho}_{2K} +\n",
      "   179                                               \\hat{\\rho}_{2K+1}` is still positive.\n",
      "   180                                           \n",
      "   181                                               The current implementation is similar to Stan, which uses Geyer's initial monotone sequence\n",
      "   182                                               criterion (Geyer, 1992; Geyer, 2011).\n",
      "   183                                           \n",
      "   184                                               References\n",
      "   185                                               ----------\n",
      "   186                                               * Vehtari et al. (2019) see https://arxiv.org/abs/1903.08008\n",
      "   187                                               * https://mc-stan.org/docs/2_18/reference-manual/effective-sample-size-section.html\n",
      "   188                                                 Section 15.4.2\n",
      "   189                                               * Gelman et al. BDA (2014) Formula 11.8\n",
      "   190                                           \n",
      "   191                                               Examples\n",
      "   192                                               --------\n",
      "   193                                               Calculate the effective_sample_size using the default arguments:\n",
      "   194                                           \n",
      "   195                                               .. ipython::\n",
      "   196                                           \n",
      "   197                                                   In [1]: import arviz as az\n",
      "   198                                                      ...: data = az.load_arviz_data('non_centered_eight')\n",
      "   199                                                      ...: az.ess(data)\n",
      "   200                                           \n",
      "   201                                               Calculate the ress of some of the variables\n",
      "   202                                           \n",
      "   203                                               .. ipython::\n",
      "   204                                           \n",
      "   205                                                   In [1]: az.ess(data, relative=True, var_names=[\"mu\", \"theta_t\"])\n",
      "   206                                           \n",
      "   207                                               \"\"\"\n",
      "   208                                               methods = {\n",
      "   209         1          4.0      4.0      0.0          \"bulk\": _ess_bulk,\n",
      "   210         1          3.0      3.0      0.0          \"tail\": _ess_tail,\n",
      "   211         1          2.0      2.0      0.0          \"quantile\": _ess_quantile,\n",
      "   212         1          2.0      2.0      0.0          \"mean\": _ess_mean,\n",
      "   213         1          2.0      2.0      0.0          \"sd\": _ess_sd,\n",
      "   214         1          2.0      2.0      0.0          \"median\": _ess_median,\n",
      "   215         1          1.0      1.0      0.0          \"mad\": _ess_mad,\n",
      "   216         1          2.0      2.0      0.0          \"z_scale\": _ess_z_scale,\n",
      "   217         1          1.0      1.0      0.0          \"folded\": _ess_folded,\n",
      "   218         1          3.0      3.0      0.0          \"identity\": _ess_identity,\n",
      "   219                                               }\n",
      "   220                                           \n",
      "   221         1          2.0      2.0      0.0      if method not in methods:\n",
      "   222                                                   raise TypeError(\n",
      "   223                                                       \"ESS method {} not found. Valid methods are:\\n{}\".format(method, \"\\n    \".join(methods))\n",
      "   224                                                   )\n",
      "   225         1          2.0      2.0      0.0      ess_func = methods[method]\n",
      "   226                                           \n",
      "   227         1          2.0      2.0      0.0      if (method == \"quantile\") and prob is None:\n",
      "   228                                                   raise TypeError(\"Quantile (prob) information needs to be defined.\")\n",
      "   229                                           \n",
      "   230         1          5.0      5.0      0.0      if isinstance(data, np.ndarray):\n",
      "   231         1         24.0     24.0      0.0          data = np.atleast_2d(data)\n",
      "   232         1          4.0      4.0      0.0          if len(data.shape) < 3:\n",
      "   233         1          2.0      2.0      0.0              if prob is not None:\n",
      "   234                                                           return ess_func(  # pylint: disable=unexpected-keyword-arg\n",
      "   235                                                               data, prob=prob, relative=relative\n",
      "   236                                                           )\n",
      "   237                                                       else:\n",
      "   238         1     572698.0 572698.0    100.0                  return ess_func(data, relative=relative)\n",
      "   239                                                   else:\n",
      "   240                                                       msg = (\n",
      "   241                                                           \"Only uni-dimensional ndarray variables are supported.\"\n",
      "   242                                                           \" Please transform first to dataset with `az.convert_to_dataset`.\"\n",
      "   243                                                       )\n",
      "   244                                                       raise TypeError(msg)\n",
      "   245                                           \n",
      "   246                                               dataset = convert_to_dataset(data, group=\"posterior\")\n",
      "   247                                               var_names = _var_names(var_names, dataset)\n",
      "   248                                           \n",
      "   249                                               dataset = dataset if var_names is None else dataset[var_names]\n",
      "   250                                           \n",
      "   251                                               ufunc_kwargs = {\"ravel\": False}\n",
      "   252                                               func_kwargs = {\"relative\": relative} if prob is None else {\"prob\": prob, \"relative\": relative}\n",
      "   253                                               return _wrap_xarray_ufunc(ess_func, dataset, ufunc_kwargs=ufunc_kwargs, func_kwargs=func_kwargs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(az.ess)\n",
    "wrapper(numpy_data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.602527 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: ess at line 132\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   132                                           def ess(data, *, var_names=None, method=\"bulk\", relative=False, prob=None):\n",
      "   133                                               r\"\"\"Calculate estimate of the effective sample size.\n",
      "   134                                           \n",
      "   135                                               Parameters\n",
      "   136                                               ----------\n",
      "   137                                               data : obj\n",
      "   138                                                   Any object that can be converted to an az.InferenceData object.\n",
      "   139                                                   Refer to documentation of az.convert_to_dataset for details.\n",
      "   140                                                   For ndarray: shape = (chain, draw).\n",
      "   141                                                   For n-dimensional ndarray transform first to dataset with az.convert_to_dataset.\n",
      "   142                                               var_names : list\n",
      "   143                                                   Names of variables to include in the effective_sample_size_mean report\n",
      "   144                                               method : str\n",
      "   145                                                   Select ess method. Valid methods are:\n",
      "   146                                           \n",
      "   147                                                   - \"bulk\"\n",
      "   148                                                   - \"tail\"     # prob, optional\n",
      "   149                                                   - \"quantile\" # prob\n",
      "   150                                                   - \"mean\" (old ess)\n",
      "   151                                                   - \"sd\"\n",
      "   152                                                   - \"median\"\n",
      "   153                                                   - \"mad\" (mean absolute deviance)\n",
      "   154                                                   - \"z_scale\"\n",
      "   155                                                   - \"folded\"\n",
      "   156                                                   - \"identity\"\n",
      "   157                                           \n",
      "   158                                               relative : bool\n",
      "   159                                                   Return relative ess\n",
      "   160                                                   `ress = ess / n`\n",
      "   161                                               prob : float, optional\n",
      "   162                                                   probability value for \"tail\" and \"quantile\" ess functions.\n",
      "   163                                           \n",
      "   164                                               Returns\n",
      "   165                                               -------\n",
      "   166                                               xarray.Dataset\n",
      "   167                                                   Return the effective sample size, :math:`\\hat{N}_{eff}`\n",
      "   168                                           \n",
      "   169                                               Notes\n",
      "   170                                               -----\n",
      "   171                                               The basic ess diagnostic is computed by:\n",
      "   172                                           \n",
      "   173                                               .. math:: \\hat{N}_{eff} = \\frac{MN}{\\hat{\\tau}}\n",
      "   174                                               .. math:: \\hat{\\tau} = -1 + 2 \\sum_{t'=0}^K \\hat{P}_{t'}\n",
      "   175                                           \n",
      "   176                                               where :math:`M` is the number of chains, :math:`N` the number of draws,\n",
      "   177                                               :math:`\\hat{\\rho}_t` is the estimated _autocorrelation at lag :math:`t`, and\n",
      "   178                                               :math:`K` is the last integer for which :math:`\\hat{P}_{K} = \\hat{\\rho}_{2K} +\n",
      "   179                                               \\hat{\\rho}_{2K+1}` is still positive.\n",
      "   180                                           \n",
      "   181                                               The current implementation is similar to Stan, which uses Geyer's initial monotone sequence\n",
      "   182                                               criterion (Geyer, 1992; Geyer, 2011).\n",
      "   183                                           \n",
      "   184                                               References\n",
      "   185                                               ----------\n",
      "   186                                               * Vehtari et al. (2019) see https://arxiv.org/abs/1903.08008\n",
      "   187                                               * https://mc-stan.org/docs/2_18/reference-manual/effective-sample-size-section.html\n",
      "   188                                                 Section 15.4.2\n",
      "   189                                               * Gelman et al. BDA (2014) Formula 11.8\n",
      "   190                                           \n",
      "   191                                               Examples\n",
      "   192                                               --------\n",
      "   193                                               Calculate the effective_sample_size using the default arguments:\n",
      "   194                                           \n",
      "   195                                               .. ipython::\n",
      "   196                                           \n",
      "   197                                                   In [1]: import arviz as az\n",
      "   198                                                      ...: data = az.load_arviz_data('non_centered_eight')\n",
      "   199                                                      ...: az.ess(data)\n",
      "   200                                           \n",
      "   201                                               Calculate the ress of some of the variables\n",
      "   202                                           \n",
      "   203                                               .. ipython::\n",
      "   204                                           \n",
      "   205                                                   In [1]: az.ess(data, relative=True, var_names=[\"mu\", \"theta_t\"])\n",
      "   206                                           \n",
      "   207                                               \"\"\"\n",
      "   208                                               methods = {\n",
      "   209         1          8.0      8.0      0.0          \"bulk\": _ess_bulk,\n",
      "   210         1          6.0      6.0      0.0          \"tail\": _ess_tail,\n",
      "   211         1          4.0      4.0      0.0          \"quantile\": _ess_quantile,\n",
      "   212         1          5.0      5.0      0.0          \"mean\": _ess_mean,\n",
      "   213         1          2.0      2.0      0.0          \"sd\": _ess_sd,\n",
      "   214         1          4.0      4.0      0.0          \"median\": _ess_median,\n",
      "   215         1          5.0      5.0      0.0          \"mad\": _ess_mad,\n",
      "   216         1          5.0      5.0      0.0          \"z_scale\": _ess_z_scale,\n",
      "   217         1          3.0      3.0      0.0          \"folded\": _ess_folded,\n",
      "   218         1          8.0      8.0      0.0          \"identity\": _ess_identity,\n",
      "   219                                               }\n",
      "   220                                           \n",
      "   221         1          4.0      4.0      0.0      if method not in methods:\n",
      "   222                                                   raise TypeError(\n",
      "   223                                                       \"ESS method {} not found. Valid methods are:\\n{}\".format(method, \"\\n    \".join(methods))\n",
      "   224                                                   )\n",
      "   225         1          5.0      5.0      0.0      ess_func = methods[method]\n",
      "   226                                           \n",
      "   227         1          4.0      4.0      0.0      if (method == \"quantile\") and prob is None:\n",
      "   228                                                   raise TypeError(\"Quantile (prob) information needs to be defined.\")\n",
      "   229                                           \n",
      "   230         1         11.0     11.0      0.0      if isinstance(data, np.ndarray):\n",
      "   231                                                   data = np.atleast_2d(data)\n",
      "   232                                                   if len(data.shape) < 3:\n",
      "   233                                                       if prob is not None:\n",
      "   234                                                           return ess_func(  # pylint: disable=unexpected-keyword-arg\n",
      "   235                                                               data, prob=prob, relative=relative\n",
      "   236                                                           )\n",
      "   237                                                       else:\n",
      "   238                                                           return ess_func(data, relative=relative)\n",
      "   239                                                   else:\n",
      "   240                                                       msg = (\n",
      "   241                                                           \"Only uni-dimensional ndarray variables are supported.\"\n",
      "   242                                                           \" Please transform first to dataset with `az.convert_to_dataset`.\"\n",
      "   243                                                       )\n",
      "   244                                                       raise TypeError(msg)\n",
      "   245                                           \n",
      "   246         1       3041.0   3041.0      0.5      dataset = convert_to_dataset(data, group=\"posterior\")\n",
      "   247         1         10.0     10.0      0.0      var_names = _var_names(var_names, dataset)\n",
      "   248                                           \n",
      "   249         1          2.0      2.0      0.0      dataset = dataset if var_names is None else dataset[var_names]\n",
      "   250                                           \n",
      "   251         1          2.0      2.0      0.0      ufunc_kwargs = {\"ravel\": False}\n",
      "   252         1          2.0      2.0      0.0      func_kwargs = {\"relative\": relative} if prob is None else {\"prob\": prob, \"relative\": relative}\n",
      "   253         1     599396.0 599396.0     99.5      return _wrap_xarray_ufunc(ess_func, dataset, ufunc_kwargs=ufunc_kwargs, func_kwargs=func_kwargs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(az.ess)\n",
    "wrapper(dict_data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocov(ary, axis=-1):\n",
    "    axis = axis if axis > 0 else len(ary.shape) + axis\n",
    "    n = ary.shape[axis]\n",
    "    m = next_fast_len(2 * n)\n",
    "    ary = ary - ary.mean(axis, keepdims=True)\n",
    "\n",
    "    # added to silence tuple warning for a submodule\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        ifft_ary = np.fft.rfft(ary, n=m, axis=axis)\n",
    "        ifft_ary *= np.conjugate(ifft_ary)\n",
    "\n",
    "        shape = tuple(\n",
    "            slice(None) if dim_len != axis else slice(0, n) for dim_len, _ in enumerate(ary.shape)\n",
    "        )\n",
    "        cov = np.fft.irfft(ifft_ary, n=m, axis=axis)[shape]\n",
    "        cov /= n\n",
    "\n",
    "    return cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocov(numpy_data,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.052147 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/stats_utils.py\n",
      "Function: autocov at line 17\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    17                                           def autocov(ary, axis=-1):\n",
      "    18                                               \"\"\"Compute autocovariance estimates for every lag for the input array.\n",
      "    19                                           \n",
      "    20                                               Parameters\n",
      "    21                                               ----------\n",
      "    22                                               ary : Numpy array\n",
      "    23                                                   An array containing MCMC samples\n",
      "    24                                           \n",
      "    25                                               Returns\n",
      "    26                                               -------\n",
      "    27                                               acov: Numpy array same size as the input array\n",
      "    28                                               \"\"\"\n",
      "    29         1          8.0      8.0      0.0      axis = axis if axis > 0 else len(ary.shape) + axis\n",
      "    30         1          3.0      3.0      0.0      n = ary.shape[axis]\n",
      "    31         1         35.0     35.0      0.1      m = next_fast_len(2 * n)\n",
      "    32                                           \n",
      "    33         1       6161.0   6161.0     11.8      ary = ary - ary.mean(axis, keepdims=True)\n",
      "    34                                           \n",
      "    35                                               # added to silence tuple warning for a submodule\n",
      "    36         1         41.0     41.0      0.1      with warnings.catch_warnings():\n",
      "    37         1         35.0     35.0      0.1          warnings.simplefilter(\"ignore\")\n",
      "    38                                           \n",
      "    39         1      15680.0  15680.0     30.1          ifft_ary = np.fft.rfft(ary, n=m, axis=axis)\n",
      "    40         1      11969.0  11969.0     23.0          ifft_ary *= np.conjugate(ifft_ary)\n",
      "    41                                           \n",
      "    42         1          5.0      5.0      0.0          shape = tuple(\n",
      "    43         1         31.0     31.0      0.1              slice(None) if dim_len != axis else slice(0, n) for dim_len, _ in enumerate(ary.shape)\n",
      "    44                                                   )\n",
      "    45         1      12230.0  12230.0     23.5          cov = np.fft.irfft(ifft_ary, n=m, axis=axis)[shape]\n",
      "    46         1       5946.0   5946.0     11.4          cov /= n\n",
      "    47                                           \n",
      "    48         1          3.0      3.0      0.0      return cov\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(az.autocov)\n",
    "wrapper(numpy_data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bottleneck :: np.fft.rfft and np.conjugate'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Bottleneck :: np.fft.rfft and np.conjugate'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fft(x,m,axis):\n",
    "    return np.fft.rfft(x,n=m,axis=axis)\n",
    "\n",
    "\n",
    "@numba.jit\n",
    "def _fft_new(x,m,axis):\n",
    "    N =  np.fft.rfft(x,n=m,axis=axis)\n",
    "    return N\n",
    "\n",
    "def conjuc(data):\n",
    "    return np.conjugate(data)\n",
    "\n",
    "\n",
    "@numba.vectorize\n",
    "def nconjuc(data):\n",
    "    return np.conjugate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.7 ms ± 669 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _fft(numpy_data,2000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6 ms ± 1.11 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _fft_new(numpy_data,2000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jitting fft is of no use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.92 ms ± 263 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit conjuc(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.conjugate([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.39 ms ± 568 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit nconjuc(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocov_new(ary, axis=-1):\n",
    "    axis = axis if axis > 0 else len(ary.shape) + axis\n",
    "    n = ary.shape[axis]\n",
    "    m = next_fast_len(2 * n)\n",
    "    ary = ary - ary.mean(axis, keepdims=True)\n",
    "\n",
    "    # added to silence tuple warning for a submodule\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        ifft_ary = np.fft.rfft(ary, n=m, axis=axis)\n",
    "        ifft_ary *= nconjuc(ifft_ary)\n",
    "\n",
    "        shape = tuple(\n",
    "            slice(None) if dim_len != axis else slice(0, n) for dim_len, _ in enumerate(ary.shape)\n",
    "        )\n",
    "        cov = np.fft.irfft(ifft_ary, n=m, axis=axis)[shape]\n",
    "        cov /= n\n",
    "\n",
    "    return cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.4 ms ± 5.63 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit autocov_new(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.3 ms ± 3.14 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit (az.autocov(numpy_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = np.random.randn(1000,1000)\n",
    "dict_data = {\"posterior\":numpy_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _z_scale(ary):\n",
    "    ary = np.asarray(ary)\n",
    "    size = ary.size\n",
    "    rank = stats.rankdata(ary, method=\"average\")\n",
    "    z = stats.norm.ppf((rank - 0.5) / size)\n",
    "    z = z.reshape(ary.shape)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.552019 s\n",
      "File: <ipython-input-62-21c5aaeb33f5>\n",
      "Function: _z_scale at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def _z_scale(ary):\n",
      "     2         1          9.0      9.0      0.0      ary = np.asarray(ary)\n",
      "     3         1          3.0      3.0      0.0      size = ary.size\n",
      "     4         1     354677.0 354677.0     64.3      rank = stats.rankdata(ary, method=\"average\")\n",
      "     5         1     197317.0 197317.0     35.7      z = stats.norm.ppf((rank - 0.5) / size)\n",
      "     6         1         12.0     12.0      0.0      z = z.reshape(ary.shape)\n",
      "     7         1          1.0      1.0      0.0      return z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(_z_scale)\n",
    "wrapper(numpy_data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def summ(x):\n",
    "    return x.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankdata_new(arr):\n",
    "    arr = np.ravel(arr)\n",
    "    sorter = np.argsort(arr, kind=\"quicksort\")\n",
    "    inv = np.empty(sorter.size, dtype=np.intp)\n",
    "    inv = inv_sorter(inv,sorter)\n",
    "    arr = arr[sorter]\n",
    "    obs = np.r_[True, arr[1:] != arr[:-1]]\n",
    "    dense = summ(obs)[inv]\n",
    "    count = np.r_[np.nonzero(obs)[0], len(obs)]\n",
    "    return av(count,dense)\n",
    "\n",
    "\n",
    "@numba.njit(cache=True)\n",
    "def inv_sorter(inv,sorter):\n",
    "    inv[sorter] = np.arange(sorter.size)\n",
    "    return inv\n",
    "\n",
    "@numba.njit(cache=True)\n",
    "def av(count, dense):\n",
    "    return .5 * (count[dense] + count[dense - 1] + 1)\n",
    "\n",
    "def av_nojit(count,dense):\n",
    "    return .5 * (count[dense] + count[dense - 1] + 1)\n",
    "\n",
    "\n",
    "def no_jit_inv_sorter(inv,sorter):\n",
    "    inv[sorter] = np.arange(sorter.size)\n",
    "    return inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.4 ms ± 2.58 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit av(np.random.randn(1000000), np.random.randint(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.8 ms ± 1.75 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit av_nojit(np.random.randn(1000000), np.random.randint(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   47,   93,  139,  185,  231,  277,  323,  369,  415,  461,\n",
       "        507,  553,  599,  645,  691,  737,  783,  829,  875,  921,  967,\n",
       "       1013, 1059, 1105, 1151, 1197, 1243, 1289, 1335, 1381, 1427, 1473,\n",
       "       1519, 1565, 1611, 1657, 1703, 1749, 1795, 1841, 1887, 1933, 1979,\n",
       "       2025, 2071, 2117, 2163, 2209, 2255, 2301, 2347, 2393, 2439, 2485,\n",
       "       2531, 2577, 2623, 2669, 2715, 2761, 2807, 2853, 2899, 2945, 2991,\n",
       "       3037, 3083, 3129, 3175, 3221, 3267, 3313, 3359, 3405, 3451, 3497,\n",
       "       3543, 3589, 3635, 3681, 3727, 3773, 3819, 3865, 3911, 3957, 4003,\n",
       "       4049, 4095, 4141, 4187, 4233, 4279, 4325, 4371, 4417, 4463, 4509,\n",
       "       4555, 4601, 4647, 4693, 4739, 4785, 4831, 4877, 4923, 4969, 5015,\n",
       "       5061, 5107, 5153, 5199, 5245, 5291, 5337, 5383, 5429, 5475, 5521,\n",
       "       5567, 5613, 5659, 5705, 5751, 5797, 5843, 5889, 5935, 5981, 6027,\n",
       "       6073, 6119, 6165, 6211, 6257, 6303, 6349, 6395, 6441, 6487, 6533,\n",
       "       6579, 6625, 6671, 6717, 6763, 6809, 6855, 6901, 6947, 6993, 7039,\n",
       "       7085, 7131, 7177, 7223, 7269, 7315, 7361, 7407, 7453, 7499, 7545,\n",
       "       7591, 7637, 7683, 7729, 7775, 7821, 7867, 7913, 7959, 8005, 8051,\n",
       "       8097, 8143, 8189, 8235, 8281, 8327, 8373, 8419, 8465, 8511, 8557,\n",
       "       8603, 8649, 8695, 8741, 8787, 8833, 8879, 8925, 8971, 9017, 9063,\n",
       "       9109, 9155, 9201, 9247, 9293, 9339, 9385, 9431, 9477, 9523, 9569,\n",
       "       9615, 9661, 9707, 9753, 9799, 9845, 9891, 9937, 9983])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(1,10000,np.random.randint(100))\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.6 ms ± 1.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit inv_sorter(np.random.randn(1000000),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.1 ms ± 1.03 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit no_jit_inv_sorter(np.random.randn(1000000),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.745453 s\n",
      "File: <ipython-input-65-669031228bc7>\n",
      "Function: rankdata_new at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def rankdata_new(arr):\n",
      "     2         1         33.0     33.0      0.0      arr = np.ravel(arr)\n",
      "     3         1     255566.0 255566.0     34.3      sorter = np.argsort(arr, kind=\"quicksort\")\n",
      "     4         1         26.0     26.0      0.0      inv = np.empty(sorter.size, dtype=np.intp)\n",
      "     5         1      47078.0  47078.0      6.3      inv = inv_sorter(inv,sorter)\n",
      "     6         1      17027.0  17027.0      2.3      arr = arr[sorter]\n",
      "     7         1       1746.0   1746.0      0.2      obs = np.r_[True, arr[1:] != arr[:-1]]\n",
      "     8         1     362105.0 362105.0     48.6      dense = summ(obs)[inv]\n",
      "     9         1       4342.0   4342.0      0.6      count = np.r_[np.nonzero(obs)[0], len(obs)]\n",
      "    10         1      57530.0  57530.0      7.7      return av(count,dense)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(rankdata_new)\n",
    "wrapper(numpy_data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.ravel(numpy_data)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.74 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "14 µs ± 10.9 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit summ(np.random.randn(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.3 µs ± 765 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.cumsum(np.random.randn(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.alltrue(summ(x)==np.cumsum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358 ms ± 19.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rankdata_new(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362 ms ± 10.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit stats.rankdata(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "school = az.load_arviz_data(\"centered_eight\").posterior[\"mu\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304 µs ± 10.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rankdata_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383 µs ± 18.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit stats.rankdata(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.alltrue(rankdata_new(school)==stats.rankdata(school))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([576575.,  20145., 400215., ..., 718170., 902640., 397462.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankdata_new(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.alltrue(stats.rankdata(x)==rankdata_new(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _z_scale_new(ary):\n",
    "    ary = np.asarray(ary)\n",
    "    size= ary.size\n",
    "    rank = rankdata_new(ary)\n",
    "    z = stats.norm.ppf((rank - 0.5) / size)\n",
    "    z = z.reshape(ary.shape)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515 ms ± 10.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _z_scale_new(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 ms ± 37.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _z_scale(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_z_scale_new(numpy_data),_z_scale(numpy_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 ms ± 8.01 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _z_scale(az.load_arviz_data(\"centered_eight\").sample_stats.log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 ms ± 7.19 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _z_scale_new(az.load_arviz_data(\"centered_eight\").sample_stats.log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 ms ± 1.75 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _z_scale(az.load_arviz_data(\"centered_eight\").posterior[\"mu\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 ms ± 12.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _z_scale_new(az.load_arviz_data(\"centered_eight\").posterior[\"mu\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"''z_scale works well on large sets. It's a bit slow on schools though\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''''''''''''''''''''''''''''''''''z_scale works well on large sets. It's a bit slow on schools though'''''''''''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def _var_1d(data):\n",
    "    a,b = 0,0\n",
    "    for i in data:\n",
    "        a = a+i\n",
    "        b = b+i*i\n",
    "    return b/(len(data))-((a/(len(data)))**2)\n",
    "\n",
    "@numba.njit\n",
    "def _var_2d(data):\n",
    "    a,b = data.shape\n",
    "    var = np.zeros(a)\n",
    "    for i in range(0,a):\n",
    "        var[i] = _var_1d(data[i,:])\n",
    "    return var\n",
    "\n",
    "\n",
    "\n",
    "def _rhat_new(ary):\n",
    "    ary = np.asarray(ary, dtype=float)\n",
    "    if _not_valid(ary, check_shape=False):\n",
    "        return np.nan\n",
    "    _, num_samples = ary.shape\n",
    "\n",
    "    # Calculate chain mean\n",
    "    chain_mean = np.mean(ary, axis=1)\n",
    "    # Calculate chain variance\n",
    "    chain_var = _var_2d(ary)\n",
    "    # Calculate between-chain variance\n",
    "    between_chain_variance = num_samples * _var_1d(chain_mean)\n",
    "    # Calculate within-chain variance\n",
    "    within_chain_variance = np.mean(chain_var)\n",
    "    # Estimate of marginal posterior variance\n",
    "    rhat_value = np.sqrt(\n",
    "        (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n",
    "    )\n",
    "    return rhat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999832532382178"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_rhat(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999832532382178"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " _rhat_new(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "school = az.load_arviz_data(\"centered_eight\").posterior[\"mu\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.01563316512969"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_rhat(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0115252895535172"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_rhat_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rhat_rank_new(ary):\n",
    "    ary = np.asarray(ary)\n",
    "    if _not_valid(ary, shape_kwargs=dict(min_draws=4, min_chains=2)):\n",
    "        return np.nan\n",
    "    split_ary = _split_chains(ary)\n",
    "    rhat_bulk = _rhat_new(_z_scale_new(split_ary))\n",
    "\n",
    "    split_ary_folded = abs(split_ary - np.median(split_ary))\n",
    "    rhat_tail = _rhat_new(_z_scale_new(split_ary_folded))\n",
    "\n",
    "    rhat_rank = max(rhat_bulk, rhat_tail)\n",
    "    return rhat_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.37711934, 12.14856451, 11.91083021, 12.97533472])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(school,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.37711934, 12.14856451, 11.91083021, 12.97533472])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_var_2d(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0115252895535172"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " _rhat_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.01563316512969"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_rhat(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17 s ± 68.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _rhat_rank_new(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 s ± 80.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rk(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.38 ms ± 17.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit _rhat_rank_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.98 ms ± 328 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit rk(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _z_fold(ary):\n",
    "    \"\"\"Fold and z-scale values.\"\"\"\n",
    "    ary = np.asarray(ary)\n",
    "    ary = abs(ary - np.median(ary))\n",
    "    ary = _z_scale_new(ary)\n",
    "    return ary\n",
    "\n",
    "\n",
    "def _rhat_folded_new(ary):\n",
    "    \"\"\"Calculate split-Rhat for folded z-values.\"\"\"\n",
    "    ary = np.asarray(ary)\n",
    "    if _not_valid(ary, shape_kwargs=dict(min_draws=4, min_chains=2)):\n",
    "        return np.nan\n",
    "    ary = _z_fold(_split_chains(ary))\n",
    "    return _rhat_new(ary)\n",
    "\n",
    "\n",
    "def _rhat_z_scale_new(ary):\n",
    "    ary = np.asarray(ary)\n",
    "    if _not_valid(ary, shape_kwargs=dict(min_draws=4, min_chains=2)):\n",
    "        return np.nan\n",
    "    return _rhat_new(_z_scale_new(_split_chains(ary)))\n",
    "\n",
    "\n",
    "def _rhat_split_new(ary):\n",
    "    ary = np.asarray(ary)\n",
    "    if _not_valid(ary, shape_kwargs=dict(min_draws=4, min_chains=2)):\n",
    "        return np.nan\n",
    "    return _rhat_new(_split_chains(ary))\n",
    "\n",
    "\n",
    "def _rhat_identity_new(ary):\n",
    "    ary = np.asarray(ary)\n",
    "    if _not_valid(ary, shape_kwargs=dict(min_draws=4, min_chains=2)):\n",
    "        return np.nan\n",
    "    return _rhat_new(ary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhat_new(data, *, var_names=None, method=\"rank\"):\n",
    "\n",
    "    methods = {\n",
    "        \"rank\": _rhat_rank_new,\n",
    "        \"split\": _rhat_split_new,\n",
    "        \"folded\": _rhat_folded_new,\n",
    "        \"z_scale\": _rhat_z_scale_new,\n",
    "        \"identity\": _rhat_identity_new,\n",
    "    }\n",
    "    if method not in methods:\n",
    "        raise TypeError(\n",
    "            \"R-hat method {} not found. Valid methods are:\\n{}\".format(\n",
    "                method, \"\\n    \".join(methods)\n",
    "            )\n",
    "        )\n",
    "    rhat_func = methods[method]\n",
    "\n",
    "    if isinstance(data, np.ndarray):\n",
    "        data = np.atleast_2d(data)\n",
    "        if len(data.shape) < 3:\n",
    "            return rhat_func(data)\n",
    "        else:\n",
    "            msg = (\n",
    "                \"Only uni-dimensional ndarray variables are supported.\"\n",
    "                \" Please transform first to dataset with `az.convert_to_dataset`.\"\n",
    "            )\n",
    "            raise TypeError(msg)\n",
    "\n",
    "    dataset = convert_to_dataset(data, group=\"posterior\")\n",
    "    var_names = _var_names(var_names, dataset)\n",
    "\n",
    "    dataset = dataset if var_names is None else dataset[var_names]\n",
    "\n",
    "    ufunc_kwargs = {\"ravel\": False}\n",
    "    func_kwargs = {}\n",
    "    return _wrap_xarray_ufunc(\n",
    "        rhat_func, dataset, ufunc_kwargs=ufunc_kwargs, func_kwargs=func_kwargs\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = np.random.randn(10000,1000)\n",
    "dict_data = {\"posterior\":numpy_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.7 s ± 551 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rh(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8 s ± 1.09 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rhat_new(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 ms ± 12.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rh(numpy_data, method='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 ms ± 11.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rhat_new(numpy_data, method='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.52 s ± 1.24 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rh(numpy_data, method='folded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.96 s ± 100 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rhat_new(numpy_data, method='folded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.93 s ± 160 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rh(numpy_data, method='z_scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.58 s ± 138 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rhat_new(numpy_data, method='z_scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 ms ± 4.54 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rh(numpy_data, method=\"identity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.3 ms ± 2.14 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rhat_new(numpy_data, method=\"identity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.38 ms ± 227 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rh(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9 ms ± 149 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rhat_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327 µs ± 22.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rh(school, method='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 µs ± 19.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rhat_new(school, method='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93 ms ± 153 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rh(school, method='folded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.47 ms ± 92.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rhat_new(school, method='folded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.38 ms ± 108 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rh(school, method='z_scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19 ms ± 55 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rhat_new(school, method='z_scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 µs ± 24.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rh(school, method='identity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 µs ± 17.1 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rhat_new(school, method='identity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good Improvement in rhat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\\'ESS'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"'ESS\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(1000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def loop_lifter(n_chain,n_draw,acov,chain_mean, mean_var, var_plus,rho_hat_t,rho_hat_even,rho_hat_odd,relative):\n",
    "    t = 1\n",
    "    while t < (n_draw - 3) and (rho_hat_even + rho_hat_odd) > 0.0:\n",
    "        rho_hat_even = 1.0 - (mean_var - np.mean(acov[:, t + 1])) / var_plus\n",
    "        rho_hat_odd = 1.0 - (mean_var - np.mean(acov[:, t + 2])) / var_plus\n",
    "        if (rho_hat_even + rho_hat_odd) >= 0:\n",
    "            rho_hat_t[t + 1] = rho_hat_even\n",
    "            rho_hat_t[t + 2] = rho_hat_odd\n",
    "        t += 2\n",
    "\n",
    "    max_t = t - 2\n",
    "    # improve estimation\n",
    "    if rho_hat_even > 0:\n",
    "        rho_hat_t[max_t + 1] = rho_hat_even\n",
    "    # Geyer's initial monotone sequence\n",
    "    t = 1\n",
    "    while t <= max_t - 2:\n",
    "        if (rho_hat_t[t + 1] + rho_hat_t[t + 2]) > (rho_hat_t[t - 1] + rho_hat_t[t]):\n",
    "            rho_hat_t[t + 1] = (rho_hat_t[t - 1] + rho_hat_t[t]) / 2.0\n",
    "            rho_hat_t[t + 2] = rho_hat_t[t + 1]\n",
    "        t += 2\n",
    "\n",
    "    ess = n_chain * n_draw\n",
    "    tau_hat = -1.0 + 2.0 * np.sum(rho_hat_t[: max_t + 1]) + np.sum(rho_hat_t[max_t + 1 : max_t + 2])\n",
    "    tau_hat = max(tau_hat, 1 / np.log10(ess))\n",
    "    ess = (1 if relative else ess) / tau_hat\n",
    "    if np.isnan(rho_hat_t).any():\n",
    "        ess = np.nan\n",
    "    return ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _ess_new(ary, relative=False):\n",
    "    \"\"\"Compute the effective sample size for a 2D array.\"\"\"\n",
    "    ary = np.asarray(ary, dtype=float)\n",
    "    if _not_valid(ary, check_shape=False):\n",
    "        return np.nan\n",
    "    if (np.max(ary) - np.min(ary)) < np.finfo(float).resolution:  # pylint: disable=no-member\n",
    "        return ary.size\n",
    "    if len(ary.shape) < 2:\n",
    "        ary = np.atleast_2d(ary)\n",
    "    n_chain, n_draw = ary.shape\n",
    "    acov = _autocov(ary, axis=1)\n",
    "    chain_mean = ary.mean(axis=1)\n",
    "    mean_var = np.mean(acov[:, 0]) * n_draw / (n_draw - 1.0)\n",
    "    var_plus = mean_var * (n_draw - 1.0) / n_draw\n",
    "    if n_chain > 1:\n",
    "        var_plus += np.var(chain_mean, ddof=1)\n",
    "\n",
    "    rho_hat_t = np.zeros(n_draw)\n",
    "    rho_hat_even = 1.0\n",
    "    rho_hat_t[0] = rho_hat_even\n",
    "    rho_hat_odd = 1.0 - (mean_var - np.mean(acov[:, 1])) / var_plus\n",
    "    rho_hat_t[1] = rho_hat_odd\n",
    "    \n",
    "    ess = loop_lifter(n_chain,n_draw,acov,chain_mean, mean_var, var_plus,rho_hat_t,rho_hat_even,rho_hat_odd,relative)\n",
    "    return ess\n",
    "\n",
    "    # Geyer's initial positive sequence\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(_ess_new(data), es(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.8 ms ± 5.03 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ess_new(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.2 ms ± 806 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit es(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ess cannot be improved further.There is no point in testing other _ess methods as all of them involve _ess func at one point or another\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(1000,1000)\n",
    "school = az.load_arviz_data(\"centered_eight\").posterior[\"mu\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.057905 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: _mcse_mean at line 860\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   860                                           def _mcse_mean(ary):\n",
      "   861                                               \"\"\"Compute the Markov Chain mean error.\"\"\"\n",
      "   862         1          8.0      8.0      0.0      ary = np.asarray(ary)\n",
      "   863         1       1765.0   1765.0      3.0      if _not_valid(ary, shape_kwargs=dict(min_draws=4, min_chains=1)):\n",
      "   864                                                   return np.nan\n",
      "   865         1      49014.0  49014.0     84.6      ess = _ess_mean(ary)\n",
      "   866         1       7109.0   7109.0     12.3      sd = np.std(ary, ddof=1)\n",
      "   867         1          8.0      8.0      0.0      mcse_mean_value = sd / np.sqrt(ess)\n",
      "   868         1          1.0      1.0      0.0      return mcse_mean_value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(_mcse_mean)\n",
    "wrapper(data)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95 ms ± 102 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit np.sqrt(_var_2d(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.59 ms ± 747 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit np.std(data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.allclose(np.sqrt(_var_2d(data)),np.std(data,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mcse_mean_new(ary):\n",
    "    ary = np.asarray(ary)\n",
    "    if _not_valid(ary, shape_kwargs=dict(min_draws=4, min_chains=1)):\n",
    "        return np.nan\n",
    "    ess = _ess_mean(ary)\n",
    "    ary = np.ravel(ary)\n",
    "    sd = np.sqrt(_var_1d(ary))\n",
    "    mcse_mean_value = sd / np.sqrt(ess)\n",
    "    return mcse_mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000005000003742"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mcse_mean(data)/_mcse_mean_new(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000250093789082"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mcse_mean(school)/_mcse_mean_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000674047731067"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(_var_1d(np.ravel(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0006745480684656"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(data,ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4858944648051677"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(_var_1d(np.ravel(school)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4867662653602105"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(school,ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.1 ms ± 10.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _mcse_mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.7 ms ± 3.14 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _mcse_mean_new(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.04 ms ± 230 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _mcse_mean_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.27 ms ± 362 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _mcse_mean(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mcse_sd_new(ary):\n",
    "    \"\"\"Compute the Markov Chain sd error.\"\"\"\n",
    "    ary = np.asarray(ary)\n",
    "    if _not_valid(ary, shape_kwargs=dict(min_draws=4, min_chains=1)):\n",
    "        return np.nan\n",
    "    ess = _ess_sd(ary)\n",
    "    ary = np.ravel(ary)\n",
    "    sd = np.sqrt(_var_1d(ary))\n",
    "    fac_mcse_sd = np.sqrt(np.exp(1) * (1 - 1 / ess) ** (ess - 1) - 1)\n",
    "    mcse_sd_value = sd * fac_mcse_sd\n",
    "    return mcse_sd_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007068803404174883"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mcse_sd_new(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007068806938579233"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msd(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1856619288742948"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mcse_sd_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18570836176957523"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msd(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 ms ± 5.49 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _mcse_sd_new(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 ms ± 1.97 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit msd(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.08 ms ± 217 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _mcse_sd_new(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.39 ms ± 289 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit msd(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _circfuncs_common(samples, high, low):\n",
    "    samples = np.asarray(samples)\n",
    "    if samples.size == 0:\n",
    "        return np.nan, np.nan\n",
    "    return samples, angle(samples, low,high,np.pi)\n",
    "\n",
    "@numba.vectorize(nopython=True)\n",
    "def angle(samples,low,high,pi=np.pi):\n",
    "    ang = (samples - low)*2.*pi / (high - low)\n",
    "    return ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _circular_standard_deviation(samples, high=2*np.pi, low=0, axis=None):\n",
    "    pi = np.pi\n",
    "    samples, ang = _circfuncs_common(samples, high, low)\n",
    "    S = np.sin(ang).mean(axis=axis)\n",
    "    C = np.cos(ang).mean(axis=axis)\n",
    "    R = np.hypot(S, C)\n",
    "    return ((high - low)/2.0/pi) * np.sqrt(-2*np.log(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.328963 s\n",
      "File: /home/banzee/Desktop/arviz/arviz/stats/diagnostics.py\n",
      "Function: _mc_error at line 892\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   892                                           def _mc_error(ary, batches=5, circular=False):\n",
      "   893                                               \"\"\"Calculate the simulation standard error, accounting for non-independent samples.\n",
      "   894                                           \n",
      "   895                                               The trace is divided into batches, and the standard deviation of the batch\n",
      "   896                                               means is calculated.\n",
      "   897                                           \n",
      "   898                                               Parameters\n",
      "   899                                               ----------\n",
      "   900                                               ary : Numpy array\n",
      "   901                                                   An array containing MCMC samples\n",
      "   902                                               batches : integer\n",
      "   903                                                   Number of batches\n",
      "   904                                               circular : bool\n",
      "   905                                                   Whether to compute the error taking into account `ary` is a circular variable\n",
      "   906                                                   (in the range [-np.pi, np.pi]) or not. Defaults to False (i.e non-circular variables).\n",
      "   907                                           \n",
      "   908                                               Returns\n",
      "   909                                               -------\n",
      "   910                                               mc_error : float\n",
      "   911                                                   Simulation standard error\n",
      "   912                                               \"\"\"\n",
      "   913      1001       2875.0      2.9      0.9      if ary.ndim > 1:\n",
      "   914                                           \n",
      "   915         1          7.0      7.0      0.0          dims = np.shape(ary)\n",
      "   916         1       5448.0   5448.0      1.7          trace = np.transpose([t.ravel() for t in ary])\n",
      "   917                                           \n",
      "   918         1         15.0     15.0      0.0          return np.reshape([_mc_error(t, batches) for t in trace], dims[1:])\n",
      "   919                                           \n",
      "   920                                               else:\n",
      "   921      1000      68807.0     68.8     20.9          if _not_valid(ary, check_shape=False):\n",
      "   922                                                       return np.nan\n",
      "   923      1000       2707.0      2.7      0.8          if batches == 1:\n",
      "   924                                                       if circular:\n",
      "   925                                                           std = stats.circstd(ary, high=np.pi, low=-np.pi)\n",
      "   926                                                       else:\n",
      "   927                                                           std = np.std(ary)\n",
      "   928                                                       return std / np.sqrt(len(ary))\n",
      "   929                                           \n",
      "   930      1000      71592.0     71.6     21.8          batched_traces = np.resize(ary, (batches, int(len(ary) / batches)))\n",
      "   931                                           \n",
      "   932      1000       2500.0      2.5      0.8          if circular:\n",
      "   933                                                       means = stats.circmean(batched_traces, high=np.pi, low=-np.pi, axis=1)\n",
      "   934                                                       std = stats.circstd(means, high=np.pi, low=-np.pi)\n",
      "   935                                                   else:\n",
      "   936      1000      60373.0     60.4     18.4              means = np.mean(batched_traces, 1)\n",
      "   937      1000     105982.0    106.0     32.2              std = np.std(means)\n",
      "   938                                           \n",
      "   939      1000       8657.0      8.7      2.6          return std / np.sqrt(batches)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp = LineProfiler()\n",
    "wrapper = lp(me)\n",
    "wrapper(data,20,True)\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mc_error_new(ary, batches=5, circular=False):\n",
    "    if ary.ndim > 1:\n",
    "\n",
    "        dims = np.shape(ary)\n",
    "        trace = np.transpose([t.ravel() for t in ary])\n",
    "\n",
    "        return np.reshape([_mc_error(t, batches) for t in trace], dims[1:])\n",
    "\n",
    "    else:\n",
    "        if _not_valid(ary, check_shape=False):\n",
    "            return np.nan\n",
    "        if batches == 1:\n",
    "            if circular:\n",
    "                std = _circular_standard_deviation(ary, high=np.pi, low=-np.pi)\n",
    "            else:\n",
    "                std = np.sqrt(_var_1d(ary))\n",
    "            return std / np.sqrt(len(ary))\n",
    "\n",
    "        batched_traces = np.resize(ary, (batches, int(len(ary) / batches)))\n",
    "\n",
    "        if circular:\n",
    "            means = stats.circmean(batched_traces, high=np.pi, low=-np.pi, axis=1)\n",
    "            std = _circular_standard_deviation(means, high=np.pi, low=-np.pi)\n",
    "        else:\n",
    "            means = np.mean(batched_traces, 1)\n",
    "            std = np.sqrt(_var_1d(means))\n",
    "\n",
    "        return std / np.sqrt(batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_mc_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-955026a6928f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_mc_error_new(data, circular=True)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2129\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-61>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1096\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-170-91084204f77c>\u001b[0m in \u001b[0;36m_mc_error_new\u001b[0;34m(ary, batches, circular)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_mc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-170-91084204f77c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_mc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_mc_error' is not defined"
     ]
    }
   ],
   "source": [
    "%timeit _mc_error_new(data, circular=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit me(data, circular=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit _mc_error_new(school, circular=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit me(school, circular=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################DONE####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def med(data):\n",
    "    x = len(data)\n",
    "    for i in range(0,x-1):\n",
    "        for j in range(0,x-i):\n",
    "            if data[i]<data[j]:\n",
    "                temp = data[i]\n",
    "                data[i]=data[j]\n",
    "                data[j]=temp\n",
    "    if x%2 != 0:\n",
    "        return data[(x-1)//2]\n",
    "    else:\n",
    "        x = x//2\n",
    "        return (data[x]+data[x-1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.37 s ± 5.24 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit med(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 ms ± 58.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.median(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med(data)==np.median(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
